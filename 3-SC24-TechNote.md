# 1 - å¤ç°å·¥ä½œ

## 1.1 ByteTransformer

+ åŸºäºpytorchçš„Transformer -  https://github.com/bytedance/ByteTransformer
+ é¦–å…ˆå¤ç°ï¼Œæ€»ä½“è¿‡ç¨‹æœ€ä¸ºæµç•… ï¼ˆgit clone  --- runè„šæœ¬ ---- å¾—åˆ° .logï¼‰ 
  + æ„Ÿå®˜ä¸Šï¼š**è½»é‡çº§ï¼Ÿ**
+ é¦–å…ˆåŸºäºdockeræ¥é…ç½®ï¼Œpullä¸‹æ¥ä¸€ä¸ªpytorch1.13+cu116
  + æ²¡æœ‰Né©±åŠ¨ã€pythonç‰ˆæœ¬ä¸åŒ¹é…ï¼›è¿›ä¸€æ­¥é…ç½®è¦æ¢æºã€ç°åœºä¸‹è½½ï¼Œå¤–é¢çœ‹ä¸åˆ°ä½ç½®
  + åœ¨anacondaä¸­åˆ›å»ºç¯å¢ƒ ByteTfæ¥è¿è¡Œï¼Œå®‰è£…ä½¿ç”¨pytorch - æ–°å®‰è£…cuda11.6

#### é—®é¢˜ ï¼š

+ åœ¨ByteTransformerçš„ä»£ç æ–‡ä»¶ä¸­ æ‰¾ä¸åˆ° cutlass.h --- æ‰‹åŠ¨å®‰è£… githubï¼šnvidia/cutlass ä½†ä¸æˆåŠŸï¼›  æœ€åä½¿ç”¨ git clone --recuseive-submoudels .....

#### é‡æ–°ç”¨Dockeræ¥å¤ç°è¯¥å·¥ä½œï¼š

+ æ‹‰å–æ–°é•œåƒ `docker pull pytorch/pytorch:1.13.0-cuda11.6-cudnn8-devel`
  + æ‹‰å–è¿‡ç¨‹ä¸­æ…¢ -- ç­‰å¾…ï½



## 1.2 TH-GNN

+ JITçš„æ¨¡å¼ å¤ç°æŠ¥é”™ --- æŸäº›moudleã€soæ–‡ä»¶ æ²¡æœ‰ç”Ÿæˆ
+ ç¯å¢ƒé…ç½®ï¼šä¸€ç³»åˆ—ç¯å¢ƒåœ¨annacondaä¸­å·²ç»å¯¹é½ï¼›ä½†æ²¡æœ‰buildæˆåŠŸ
  + **PyTorch** 1.8.0+ã€**DGL** 0.7.0+ã€**Ninja** 1.10+ã€**GPUtil** 1.4+ 
  + ç»“è®ºï¼šå¦‚æœæ˜¯ç»™çš„æŸä¸ªç¯å¢ƒ+çš„è¯ï¼Œåˆ™ç›´æ¥å‚è€ƒ**æœ€ä½çš„**é‚£ä¸ª
+ èƒ½æœ‰dockerçš„è¯åˆ™ç›´æ¥ ä½¿ç”¨docker --- condaæ¬²é€Ÿåˆ™ä¸è¾¾ï¼Œçœ‹èµ·æ¥æœ€ç¬¨å®é™…ä¸Šæœ€é¡ºåˆ©çš„æ–¹æ³•

#### é—®é¢˜1 ä»£ç è¿è¡Œ

+ `FROM nvidia/cuda:11.3.0-devel-ubuntu18.04 as base` åœ¨dockerhubä¸Šå¹¶æ²¡æœ‰æ‰¾åˆ°è¿™ä¸ªé•œåƒï¼Œäºæ˜¯

  + æ›´æ¢ç‰ˆæœ¬ä¸º`nvidia/cuda:11.3.1-devel-ubuntu18.04`å¯ä»¥æ­£å¸¸å®‰è£…

+ dokcerfile buildæ–‡ä»¶åˆ°ä¸€åŠï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªæ–‡ä»¶ è¿›åº¦åˆ° 300M/1.2GBåˆ™åœæ­¢äº†ï¼Œå°è¯•å¤šæ¬¡ï¼Œè¿›åº¦éƒ½æ²¡åŠ¨

  + Docker infoæŸ¥çœ‹`Docker Root Dir: /home/david/.local/share/docker` ç¡®å®šå®‰è£…çš„cacheï¼›æŠŠè¿™ä¸ªç›®å½•ä¸‹çš„æ–‡ä»¶åˆ æ‰ï¼Œæ‰èƒ½è·‘å®Œ
  + nvè¿™é‡Œè¦æ¸…é™¤çš„Cacheå¹¶ä¸æ˜¯ [Dockrt Build Cache](https://blog.csdn.net/catoop/article/details/128002962) ï¼›åˆ é™¤äº†è¿™äº›æ²¡æœ‰ä½¿ç”¨çš„é•œåƒï¼Œæ²¡æœ‰ä½œç”¨

+ Dockerfileä¸­çš„æ–‡ä»¶

  `COPY install/ubuntu_build.sh /install/ubuntu_build.sh
  RUN bash /install/ubuntu_build.sh`

  + å…¶ä¸­åœ¨ubuntu_buildä¸­æœ‰ä¸€é¡¹æ˜¯ï¼šwget æ¸…åé•œåƒç«™ä¸Šçš„Anaconda3-2021.05-Linux-x86_64.shï¼Œå§‹ç»ˆ403 forbidenï¼›åœ¨æˆ‘çš„ubuntuä¸Šï¼ˆä¼°è®¡æ˜¯å› ä¸ºproxyçš„åŸå› ï¼‰æ— æ³•æ­£å¸¸ä¸‹è½½ï¼Œè¿›è€Œæ— æ³•æ‰§è¡Œæ”¹è„šæœ¬
  + è§£å†³ï¼šå•ç‹¬æ‰‹åŠ¨ä¸‹è½½è¯¥è„šæœ¬ï¼Œåœ¨Dockerfileä¸­æŠŠè¿™ä¸ªCOPYè¿›Dockerï¼›ä¹‹åæ­£å¸¸æ‰§è¡Œ

+ ![](https://s3.bmp.ovh/imgs/2023/09/26/a82daabe50f11832.png)

  + è¦æƒ³åœ¨dockerä¸­ä½¿ç”¨GPUï¼Œéœ€è¦å…ˆé…ç½® [Nvidia-Container-Runtime](https://blog.csdn.net/qq_35395195/article/details/131431872)
  + Docker imagesä¸­å¯ä»¥çœ‹åˆ°è¿™ä¸ªé•œåƒï¼Œä½†æ˜¯docker runçš„æ—¶å€™è¯´æ²¡æ‰¾åˆ°


+ å…¶å®‰è£…è„šæœ¬ä¸­çš„å¯¹ä¸€äº›åŒ…çš„é…ç½®ç®¡ç†ä¸å®Œå…¨ã€ä¸ç»†è‡´
  + ç›´æ¥ä½¿ç”¨è„šæœ¬condaå®‰è£…çš„torchã€dglç­‰ï¼Œç»“æœæ˜¯æœ€æ–°ç‰ˆ
  + ç¼ºå°‘çš„åŒ…ï¼šh5py
  + [dgl](https://www.dgl.ai/pages/start.html)ã€[torch](https://pytorch.org/get-started/previous-versions/)æ²¡æœ‰å®‰è£…ä¸cuda11.3æ‰€åŒ¹é…çš„ç‰ˆæœ¬
+ [ImportError: version `GLIBCXX_3.4.22â€˜ not found](https://blog.csdn.net/qq_30653631/article/details/107620137)

#### é—®é¢˜2 æœªè§£å†³é—®é¢˜


+ å†…å­˜ä¸å¤Ÿï¼ˆ32GBï¼‰ --- å®˜æ–¹ç»™åˆ°çš„é…ç½®æ˜¯64GB

  + dmesgæŸ¥çœ‹å†…æ ¸killåŸå› ï¼Œå‘ç°æ˜¯oom -- å®¿ä¸»æœºä¸ŠdmesgæŸ¥çœ‹ï¼šå®¹å™¨å†…çš„PIDä¸dmesgä¸­çš„PIDå¹¶ä¸ä¸€æ ·
  + èƒ½å¤Ÿæ‰“å‡ºä¸€éƒ¨åˆ†çš„æ•°æ®.csvæ–‡ä»¶ï¼Œä¸èƒ½æ‰“å‡ºå›¾ç‰‡
+ å…³äºDGLåº“çš„é—®é¢˜ AttributeError: 'RedditDataset' object has no attribute 'num_labels'

  + DGLçš„ç‰ˆæœ¬è¿‡é«˜ï¼ˆ1.1.2ï¼‰ --- åœ¨0.5.0ä»¥ååˆ™å¼ƒç”¨ --- readmeå†™çš„0.7.0+
  + å®‰è£…æ›´ä½çš„ç‰ˆæœ¬æœ‰å…¶ä»–é—®é¢˜ RuntimeError: Bool type is not supported by dlpack

    + torchä¸ä¹‹å…³ç³»ä¸åŒ¹é…

#### è¿è¡Œåœè½¦ å°ç»“

+ torchã€dglã€cudaç‰ˆæœ¬å¯¹é½çš„é—®é¢˜ï¼Œä¾æ®dockerå’Œå®˜ç½‘æ‰€ç»™ çš„å¹¶ä¸èƒ½å®Œå…¨æˆåŠŸè¿è¡Œ ï¼›ç¡¬ä»¶é…ç½®ï¼šå†…å­˜ä¸å¤Ÿ 64GBï¼›ç»¼ä¸Šï¼Œèƒ½è·‘å‡ºæ¥2ä¸ªå°è§„æ¨¡çš„æ•°æ® .csvï¼Œè®¤ä¸ºä»»åŠ¡å·²ç»è·‘é€šï¼Œä¸å†æ·±ç©¶å®Œå…¨è·‘é€š



æœ¬å·¥ä½œæœ‰Dockerfileï¼›å¯ä»¥ç›´æ¥ç”¨æ¥æ‹‰å–é•œåƒ

+ åˆ›å»ºå®¹å™¨ ```sudo docker run --gpus 0 --name ByteTranformer -itd -v /home/david/ATC24/ByteTransformer:/Byte gnn:v1 /bin/bash```
  + å¯ä»¥ä½¿ç”¨å®¿ä¸»çš„ Nvidia é©±åŠ¨ï¼›
  + æ–°å»ºçš„å®¹å™¨ å‘½åä¸ºByteTranformer
  + æŠŠå®¿ä¸»çš„æ–‡ä»¶æŒ‚è½½åœ¨dockerä¸Š
  + å®¹å™¨åˆ›å»ºè¿è¡Œ æŒ‚åœ¨åå°è·‘ ï¼›å†ç”¨ docker exec -it ã€NAME / container IDã€‘è¿›å…¥



## 1.3 FeatGraph - SC20

> å®ç°å‰è¨€ - å®Œå…¨ä½¿ç”¨Dockeræ¥è¿›è¡Œä»¥ä¸‹çš„æ‰€æœ‰æ“ä½œï¼›ç”±äºç¼–è¯‘çš„å„ç§æ“ä½œï¼Œå·²ç»ä¸æ˜¯ç®¡ç†pipåŒ…é‚£ä¹ˆç®€å•äº†ï¼Œç§ç§ç¯å¢ƒçš„å½±å“ä¸‹ï¼ŒDockerå°±æ˜¯æœ€ä¼˜è§£ï¼ˆ1ï¼‰ä¸å½±å“å…¶ä»–ç¯å¢ƒ ï¼ˆ2ï¼‰æ¨å€’é‡æ¥çš„è½»é‡çº§

Dockeråˆ›å»ºå®¹å™¨ ï¼Œå‘½åä¸º**FeatGraph-SC20**ï¼Œä½¿ç”¨çš„é•œåƒè¿˜æ˜¯ ubuntu20 + cu116

```dockerfile
docker run --gpus 0 --name FeatGraph-SC20 -itd -v /home/david/ATC24/FeatGraph:/FeatGraph pytorch/pytorch:1.13.0-cuda11.6-cudnn8-devel /bin/bash
```

æ‰§è¡Œè¯­å¥ è¿›å…¥å‘½ä»¤è¡Œçš„æ“ä½œ

```dockerfile
docker exec -it FeatGraph-SC20 /bin/bash
```

#### é—®é¢˜ï¼š

+ DGLçš„ç‰ˆæœ¬é—®é¢˜ ---l s1.1.X 
  + ä½†æ˜¯å¤ç°çš„å¤šæ•°ç¯å¢ƒï¼Œéƒ½ä¸æ”¯æŒé‚£ä¹ˆæ–°<img src = 'https://s3.bmp.ovh/imgs/2023/10/15/ecdba632d3c46431.png' >
    + é—®é¢˜1ï¼š[TypeError: adj() got an unexpected keyword argument â€˜scipy_fmtâ€™ ](https://discuss.dgl.ai/t/typeerror-adj-got-an-unexpected-keyword-argument-scipy-fmt/3755)
    + é—®é¢˜2ï¼š[Issue with AttributeError: â€˜DGLGraphâ€™ object has no attribute â€˜adjacency_matrix_scipyâ€™. ](https://discuss.dgl.ai/t/issue-with-attributeerror-dglgraph-object-has-no-attribute-adjacency-matrix-scipy/3562)


+ ä¸‹è½½æ•°æ®é›† `download_reddit_dataset.py`å¼ºåˆ¶ä¸‹è½½ - redditï¼ˆ4.3GBï¼‰

+ è¿è¡Œä»£ç `python bench_vanilla_spmm.py --dataset data/reddit_csr_float32.npz --feat-len 64 --target x86`
  + é”™è¯¯1ï¼š[TVMError: Check failed: bf != nullptr: Target llvm is not enabled](https://discuss.tvm.apache.org/t/tvmerror-check-failed-bf-nullptr-target-llvm-is-not-enabled/5561)
    + é”™è¯¯1- è§£å†³1 ï¼šåœ¨cmakeæ—¶LLVMé€‰é¡¹æœªå¼€å¯ éœ€è¦è®¾ç½®ä¸ºï¼ˆ**LLVM ON**ï¼‰
    + ä¼ç¬”ï¼šé‚£ä¹ˆï¼ˆ**CUDA OFF**ï¼‰æ˜¯å¦ä¹Ÿå¯ä»¥å¼€ --- æ‹…å¿ƒCUDAç‰ˆæœ¬çš„åŒ¹é…é—®é¢˜

  + é”™è¯¯1ï¼š å±•å¼€ï¼š åœ¨æºç å®‰è£…TVMå‰ï¼Œ**é¦–å…ˆ**è¿˜éœ€è¦ [ä»æºç å®‰è£…LLVM](https://llvm.org/docs/GettingStarted.html#getting-the-source-code-and-building-llvm) ç„¶åå†ï¼ˆ**LLVM ON**ï¼‰
    + `git clone https://github.com/llvm/llvm-project.git` LLVM gitä¸‹æ¥éå¸¸å¤§ - å¤§çº¦2GB
    + æºç å®‰è£… cmakeå¤±è´¥ï¼Œcmakeåˆ°é”™è¯¯çš„ä½ç½®è€—æ—¶çº¦30min<img src = 'https://s3.bmp.ovh/imgs/2023/10/16/34eead6e76b52d8f.png' > ä¸æ‰“ç®—debug 
    + åæŸ¥çœ‹ï¼šæºç å®‰è£…å®Œæˆä»¥åï¼ŒæŸ¥çœ‹buildæ–‡ä»¶ --- **50GBï¼**

  + é”™è¯¯2ï¼šä¾æ® æºç å®‰è£…TVMæ—¶å¯¹[LLVMçš„ä»‹ç»çš„å¦å¤–ä¸¤ç§æ–¹å¼](https://tvm.apache.org/docs/install/from_source.html#developers-get-source-from-github)  ï¼ˆ1ï¼‰â€œdownload pre-built version of LLVM from [LLVM Download Page](http://releases.llvm.org/download.html)â€ ä½†æ˜¯*æ²¡å¤ªçœ‹æ‡‚åº”è¯¥å¦‚ä½•å®‰è£…*ï¼›è€Œä¸”å¹¶ä¸æ¸…æ¥šåº”è¯¥å®‰è£…å®ƒæä¾›çš„é‚£äº›åŒ…ä¸­çš„å“ªä¸€ä¸ªï¼Ÿ--- æŸ¥çœ‹Doc é€€åŒ–åˆ°äº† æºç å®‰è£… ï¼ˆ2ï¼‰â€œYou can also use [LLVM Nightly Ubuntu Build](https://apt.llvm.org/)â€ -- è‡ªåŠ¨åŒ–è„šæœ¬å®‰è£…

    + å®˜ç½‘çš„è„šæœ¬ä½¿ç”¨ `https://apt.llvm.org/llvm.sh` å…¶ä¸­å®‰è£…æ—¶ä¼šå‘ `/etc/apt/source.list` ä¸­æ·»åŠ äº†æºï¼š 

      ```shell
      deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-17 main
      #deb-src http://apt.llvm.org/bionic/llvm-toolchain-bionic-17 main
      deb https://mirrors.tuna.tsinghua.edu.cn/llvm-apt/bionic/ llvm-toolchain-bionic-17 main
      #deb-src https://mirrors.tuna.tsinghua.edu.cn/llvm-apt/bionic/ llvm-toolchain-bionic-17 main```
      ```

      æ˜¾ç„¶è¿™ä¸ªæºå¤ªæ…¢äº†ï¼Œ28MBçš„æ–‡ä»¶ä¸‹è½½æ—¶é—´ä¸å¯æ¥å—ï¼ˆ>2hï¼‰ 

    +  æƒ³åˆ°èƒ½å¦æ¢æºæ¸…åï¼Œç­”æ¡ˆæ˜¯å¯ä»¥ï¼Œç”¨[tuna.moe - LLVMæ¸…åæº](https://mirrors.tuna.tsinghua.edu.cn/help/llvm-apt/)ï¼›

  + é”™è¯¯3ï¼š æ¸…åæºæ²¡æœ‰æœ€æ–°çš„ç‰ˆæœ¬ï¼Œæœ€æ–°ä¸º15ï¼Œæ­¤å¤„é‡‡ç”¨llvm-12 --- LLVMå®‰è£…æˆåŠŸ ï¼›ä½†tvm buildä¸æˆåŠŸï¼ŒæŠ¥äº†errorï¼Œbuildåˆ°90%åœæ­¢ï¼ŒæŠ¥é”™ä¿¡æ¯å¦‚ä¸‹ï¼ˆé—®é¢˜çŒœæµ‹æ˜¯ LLVMçš„ç‰ˆæœ¬è¿‡é«˜ï¼Œä¸TVMä¸åŒ¹é…ï¼ˆå½“å‰å®˜æ–¹æœ€æ–°ä¸º17ï¼Œæ¸…åæºæœ€æ–°15ï¼Œåˆšå®‰è£…12æˆåŠŸï¼Œä½†build tvmå¤±è´¥ï¼‰æ²¡æœ‰è¿›è¡ŒDebugï¼š

    ```shell
    FeatGraph/tvm/src/target/llvm/codegen_llvm.cc:480:82: error: no matching function for call to 'llvm::ElementCount::ElementCount(int&, bool)'
    ```

    + é€šè¿‡ç¿»é˜… FeatGraphçš„å‘å¸ƒæ—¶é—´ - å…¶æ‰€è¦æ±‚gitçš„TVM 0.7 çš„ç‰ˆæœ¬å·å‘å¸ƒæ—¶é—´â€œOct 3 2020â€ï¼›å›æº¯æŸ¥çœ‹å½“æ—¶TVMæ‰€åº”è¯¥åŸºäºçš„LLVMç‰ˆæœ¬ æ¨æµ‹ä¸ºâ€œJul 22, 2020â€çš„è¿™ç‰ˆï¼Œä¹Ÿå°±æ˜¯LLVM 10
    + æ­¤æ—¶é€‰æ‹©åœ¨å®‰è£…äº†LLVM 12çš„Dockerä¸­ä¸å†è¿›è¡Œuninstallæ“ä½œã€‚ã€**Dockerçš„ä¼˜åŠ¿ä½“ç°**ã€‘é‡æ–°åŸºäºåŒä¸€ä¸ªé•œåƒåˆ›å»ºäº†å¦ä¸€ä¸ªå®¹å™¨å®‰è£…LLVM 10åï¼ŒåŸºäºLLVMçš„TVM build æˆåŠŸ -- 100% ; ç»“åˆåˆšæ‰ä¸‹è½½çš„æ•°æ®é›†æˆåŠŸè¿è¡Œ pythonä»£ç 

#### è¿è¡Œå°ç»“ï¼š

+ è¿è¡Œè¿™ä¸ªå…³äºç¼–è¯‘å™¨çš„å·¥ä½œå°¤å…¶ä½“ç°äº†Dockerçš„ä¼˜åŠ¿ï¼šï¼ˆ1ï¼‰å®Œå…¨çš„éš”ç¦» --- ä¸å½±å“å…¶ä»–çš„**æ‰€æœ‰**ç¯å¢ƒï¼›ï¼ˆ2ï¼‰è½»é‡åŒ– --- åˆ›å»ºé…ç½®ä¸è´¹åŠ²ã€åˆ é™¤ä¸å¿ƒç–¼ã€‚ ç—›ç‚¹è§£å†³ï¼šï¼ˆ1ï¼‰GPU --- é©±åŠ¨å¯ä»¥ä¸å®¿ä¸»å…±ç”¨ï¼ˆ2ï¼‰æ–‡ä»¶æŒ‚è½½ --- Dockerä¸­çš„æ“ä½œã€ä¸‹è½½ç—•è¿¹èƒ½å¤Ÿä¸€ç›´ä¿ç•™

+ FeatGraph ---ã€‹ TVM ---ã€‹ LLVM ï¼›ç§ç§åŸºäºï¼Œç‰ˆæœ¬éƒ½è¦æ³¨æ„**å‘ä¸‹å…¼å®¹**ï¼Œæ‰€åŸºäºçš„ç‰ˆæœ¬éœ€è¦ä»¥æºç è¿›è¡Œå®‰è£…

+ 2ç»„CPUä»£ç è¿è¡ŒæˆåŠŸï¼ŒGPUçš„æ²¡æœ‰ --- ä¼°è®¡CUDAç‰ˆæœ¬ä¸€å®šä¼šå‡ºé”™ ï¼Œè¦æ±‚10åŠä»¥ä¸‹ï¼Œ3090ç¡¬ä»¶ä¸æ”¯æŒ

  `TVMError: Check failed: allow_missing: Device API gpu is not enabled.`



## 1.4 Faith - ATC22

å®‰è£…ä¹‹å‰ - github readmeï¼š`conda install tvm-cu102 -c ./conda/pkg`æ„Ÿè§‰æƒ…å†µä¸å¦™ï¼›30ç³»çš„æ˜¾å¡ä¸æ”¯æŒ10ä»£cudaå¾ˆå¯èƒ½è·‘ä¸äº†ï¼Œä½†å¯¹å…¶ä»æŠ±æœ‰ä¸€å®šçš„æœŸå¾…

Dockeråˆ›å»ºå®¹å™¨ ï¼Œå‘½åä¸º**Faith-ATC22**ï¼Œä½¿ç”¨çš„é•œåƒä¸ºäº†é…åˆåç»­çš„cuda10.2 æ‰€ä»¥ç›´æ¥æ‹‰äº†ä¸€ä¸ªæ–°çš„é•œåƒä¸‹æ¥ï¼š`bleakie/cuda10.2_cudnn8.0_ubuntu16.04:latest` åˆ›å»ºè¯­å¥:

```dockerfile
docker run --gpus 0 --name Faith-ATC22 -itd -v /home/david/ATC24/Faith:/Faith bleakie/cuda10.2_cudnn8.0_ubuntu16.04:latest /bin/bash
```

dockerå¯åŠ¨å®¹å™¨è¯­å¥

```dockerfile
docker exec -it Faith-ATC22 /bin/bash
```

+ æœ¬æ¬¡å¸¸ä½¿ç”¨åˆ°condaï¼Œäºæ˜¯é¦–å…ˆæ‹¿åˆ°æ–°çš„dockerï¼šï¼ˆ1ï¼‰æ›´æ–°aptæºubuntu16ï¼Œï¼ˆ2ï¼‰æ›´æ–°pipæºï¼ˆ3ï¼‰å®‰è£…condaå¹¶æ¢æºåˆ°æ¸…å

#### é—®é¢˜ï¼š

+ `conda env create -f environment.yml` ä¸`conda env create --file conda/build-environment.yaml` æ€»æ˜¯æœ‰ç‚¹å°é”™è¯¯ï¼Œç±»ä¼¼

  ```shell
  CondaError: Downloaded bytes did not match Content-Length
    url: https://conda.anaconda.org/anaconda/linux-64/mkl-2021.4.0-h06a4308_640.tar.bz2
    target_path: /root/anaconda3/pkgs/mkl-2021.4.0-h06a4308_640.tar.bz2
  ```

  é€šè¿‡é‡å¤æ‰§è¡Œconda env create -f è¯­å¥è§£å†³

+ readmeä¸Šç¡®æœ‰æé†’å¿…é¡»å®‰è£… cudnnä¸cublasï¼š`Remember to add cudnn and cublas into /usr/local/cuda-10.2. For adding cudnn and cublas`ï¼Œå¦åˆ™åœ¨æ‰§è¡Œ`sh conda/build_cuda.sh` æŠ¥é”™

  ```shell
  CMake Error: The following variables are used in this project, but they are set to NOTFOUND.
  Please set them or make sure they are set and tested correctly in the CMake files:
  CUDA_CUBLAS_LIBRARY
      linked by target "tvm" in directory /root/anaconda3/envs/tvm-build/conda-bld/tvm-cu102-package_1697633308207/work
      linked by target "tvm_runtime" in directory /root/anaconda3/envs/tvm-build/conda-bld/tvm-cu102-package_1697633308207/work
  ```

  + ä½†æ˜¯cublaså¹¶ä¸å•ç‹¬å®‰è£…ï¼Œè€Œæ˜¯åœ¨cudaä¸­å·²å®‰è£…ï¼›å¯¹äºcuda11ä»¥åçš„ç‰ˆæœ¬æ¥è¯´æ˜¯åœ¨`/usr/local/lib64 æˆ–è€…  /usr/local/includeä¸‹çš„æŸä¸ª .soæ–‡ä»¶`  å¯¹äºcuda10æ¥è¯´æ˜¯åœ¨`/usr/lib/x86_64-linux-gnu` --- è¿™é‡Œæ¶‰åŠåˆ°äº†cudaç‰ˆæœ¬çš„å˜åŒ–å¸¦æ¥çš„cublasè·¯å¾„å˜åŒ–ã€‚
  + å•ç‹¬`export CUDA_CUBLAS_LIBRARY= ` æ²¡æœ‰è§£å†³é—®é¢˜
  + æˆ‘æ˜¯ä½¿ç”¨dockerç›´æ¥æ‹‰ä¸‹æ¥çš„å«æœ‰cuda10.2çš„é•œåƒï¼›åœ¨cuda10.2çš„å®‰è£…æ­¥éª¤ä¸­ï¼Œæ‰“äº†è¡¥ä¸[Patch1](https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal) ï¼Œä¸‹è½½è¯¥.runæ–‡ä»¶å¹¶bashè¿è¡Œï¼Œé—®é¢˜è§£å†³ --- æ‰¾åˆ°äº†cublas

+ ä½¿ç”¨  `sh conda/build_cuda.sh`  å®é™…ä¸Šåœ¨ ç”¨cmakeçš„æ‰‹æ®µbuild tvm-cu102ï¼›ä»¥ä¸ŠæŠ¥é”™åœ¨cmakeå¼€å§‹ä»¥å‰ï¼Œcmakeåˆ°99%æ—¶ï¼ŒæŠ¥é”™

   ```shell
   make[2]: Leaving directory '$SRC_DIR/build'
   [ 99%] Built target tvm_objs
   make[1]: Leaving directory '$SRC_DIR/build'
   make: *** [Makefile:136: all] Error 2
   Traceback (most recent call last):
     File "/root/anaconda3/envs/tvm-build/bin/conda-build", line 11, in <module>
       sys.exit(main())
     ... ...
     File "/root/anaconda3/envs/tvm-build/lib/python3.7/site-packages/conda_build/utils.py", line 382, in _func_defaulting_env_to_os_environ
       raise subprocess.CalledProcessError(proc.returncode, _args)
   subprocess.CalledProcessError: Command '['/bin/bash', '-o', 'errexit', '/root/anaconda3/envs/tvm-build/conda-bld/tvm-cu102-package_1697635987468/work/conda_build.sh']' returned non-zero exit status 2.
   ```

  + è¿™ä¸ªbuildçš„é”™è¯¯å®šä½ä¸æ˜ç¡® ---- æŸ¥é˜…èµ„æ–™åè®¤ä¸ºï¼šå°½ç®¡å„ä¸ªä¾èµ–åŒ…ã€åº“éƒ½å‚ç…§äº† `conda enviroment.yaml`æ–‡ä»¶æ¥è¿›è¡Œå®‰è£…ï¼Œç¡®ä¿äº†è¿™äº›çš„ç‰ˆæœ¬åŒ¹é…å…³ç³»ï¼Œä½†æ˜¯å¯¹äºpythonã€gccç­‰ç‰ˆæœ¬ä»ç„¶ä¸èƒ½ä¿è¯å¯¹é½ï¼›æœ€é‡è¦çš„ä¸€ç‚¹ï¼šæ­¤å¤„çš„cuda10 ä¸é€‚åº”äº30ç³»æ˜¾å¡ï¼Œæ­¤å¤„çš„buildå¯èƒ½ä¹Ÿä¼šå› æ­¤å¤±è´¥

  

## è¿è¡Œåœè½¦ï¼Œç§»æ¤ä¸é‡å¼€

+ Dockerçš„ä»å¤´å®‰è£…ï¼šç¡®ä¿æœ‰ä¸€ä¸ªçº¯å‡€çš„ç¯å¢ƒï¼Œå‚è€ƒ[Tuna.moe](https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/) - Debian/Ubuntu/Raspbian çš„å®‰è£…æ‰‹æ®µï¼Œç„¶åè¿›è¡Œå®‰è£…

  + ä¸ºäº†ä½¿åœ¨ Ubuntu ä¸Šé…ç½®æ— éœ€ä½¿ç”¨ `sudo` æ¥è¿è¡Œ Docker ï¼Œè¾“å…¥ 

    ```shell
    sudo usermod -aG docker $USER  # ç„¶åé€€å‡ºç»ˆç«¯ é‡å¯
    ```

  + æ¢æºä¸º [ä¸­ç§‘å¤§ã€ç½‘æ˜“æº]( https://blog.csdn.net/m0_37282062/article/details/115770314)ï¼Œå…¶é—´é€šè¿‡docker infoæŸ¥çœ‹æ˜¯å¦æ¢æºæˆåŠŸ

+ æ‰“åŒ…dockerç¯å¢ƒå®ç°å¿«é€Ÿçš„ç§»æ¤

  + `docker pull`çš„é€Ÿåº¦å¾ˆå¤šæ—¶å€™ä¸å¯æ¥å—ï¼Œè€Œä¸”dockerä¸­æœ¬èº«å·²ç»æœ‰ä¸€å®šçš„é…ç½®äº† å¤ç”¨æ›´å¥½ã€‚
  + æƒ³æ³•1 - æ‰“åŒ…**å®¹å™¨**`docker export <å®¹å™¨ID> > container.tar`ï¼Œä¼ åˆ°å¯¹åº”ä½ç½®å(å¹¶å‘½å) `docker import container.tar test/my:v1` ä½†æ‰“åŒ…åçš„å®¹å™¨å¤ªå¤§ - Faith-ATC22ã€32GBã€‘æ„Ÿè§‰æœ‰å¾ˆå¤šå†—ä½™
  + æƒ³æ³•2 å®æ–½ - æ‰“åŒ…æ‰€éœ€**é•œåƒ**  `docker save -o image.tar <é•œåƒåç§°>`ï¼Œä¼ åˆ°å¯¹åº”ä½ç½®å `docker load -i image.tar` è¯¥é•œåƒçš„å¤§å°ä¸º5GB

+ ç§»æ¤è¿‡ç¨‹ï¼Œé‡æ–°é…ç½®

  + æ‹‰å–äº†å¤šä¸ªé•œåƒ - å¸Œæœ›æ›´åŒ¹é…paperä¸­çš„ç¯å¢ƒï¼Œä½†æœ‰å¾ˆå¤š**å…¶ä»–é—®é¢˜**
    + [tuna.moe - LLVMæ¸…åæº](https://mirrors.tuna.tsinghua.edu.cn/help/llvm-apt/)å¹¶ä¸æ”¯æŒå¯ä»¥ä¸‹è½½åˆ°LLVM-10ä½†ä¸æ”¯æŒubuntu16 -- ubuntuç‰ˆæœ¬ä¸èƒ½å¤ªä½
    + æœ‰çš„é•œåƒä¸­æ‰€åŒ…å«çš„ cuda10.2ä¸å®Œæ•´ --- æ²¡æœ‰cuda/bin -- æ‰¾ä¸åˆ°nvcc
    + æ¯æ¬¡éƒ½æ˜¯æ–°ç³»ç»Ÿé‡æ–°é…ç½®ï¼Œç³»ç»Ÿä¸Šçš„å°é—®é¢˜ --- ä¿®èµ·æ¥å¿«ä½†å¾ˆæ‚

  + **ç»“è®º**ï¼šä¸å¦‚ç›´æ¥æ‰“åŒ… **dockerç¯å¢ƒ**å®ç°å¿«é€Ÿçš„ç§»æ¤ ï¼›å³**æƒ³æ³•1**ï¼Œæœ€ç¬¨ä½†æœ€ç¨³å¦¥


### åœ¨å››èŠ‚ç‚¹ä¸Šè¿è¡Œ

+ ç™»é™†ï¼š`ssh root@10.18.19.43 -p 2005`å¯†ç  root

+ ç™»é™†ä¸Šå»è‡ªåŠ¨è¿›å…¥ä¸€ä¸ªï¼ˆæ¯ä¸ªäººè‡ªå·±çš„ï¼‰dockerï¼›æˆ‘ç°åœ¨çš„éœ€æ±‚ç­‰äºæ˜¯ ***åœ¨dockeré‡Œå†ç”¨docker***

+ Node1 çš„ä½¿ç”¨

  1. æ­£å¸¸å®‰è£…äº†docker --- å¯ä»¥åœ¨å®¹å™¨é‡Œå®‰docker

  2. åˆ›å»ºå®¹å™¨å¹¶å¯åŠ¨ï¼Œé”™è¯¯ï¼š --- GPUç›¸å…³ ä»ç„¶å‚è€ƒé…ç½® [Nvidia-Container-Runtime](https://blog.csdn.net/qq_35395195/article/details/131431872) --- é—®é¢˜è§£å†³ï¼šdockeré‡Œé¢å†å¥—dockerå¯ä»¥ä½¿ç”¨GPUï¼›å’Œå•å±‚dockeræ“ä½œå®Œå…¨ä¸€æ ·

     ```shell
     docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
     ```

+ 4èŠ‚ç‚¹è¿è¡Œå°ç»“ ---- æ€»ä½“ä¸Šæ„Ÿè§‰ä¸æ–¹ä¾¿
  + ç©ºé—´å¤ªå° ï¼šå…±ç”¨500GBï¼Œä¸€ä¸ªäºº100GBå¤šç‚¹
  + ç›®å‰æˆ‘èƒ½ç”¨node1/4ï¼›æ²¡æœ‰node2ã€3ä¸èƒ½ç”¨ï¼Œnode4åšäº†ç½‘ç»œéš”ç¦»è¿ä¸ä¸Šï¼Œnode1å…³æœºäº† 

### é‡å¼€1 - FeatGraph - SC20

+ å¯åŠ¨è¯­å¥å˜æ›´`--gpus all`ï¼Œå¦åˆ™æ²¡æ³•è¾“å‡º`nvidia-smi`ï¼ˆæ—¢ä¸æŠ¥é”™ä¹Ÿæ²¡è¾“å‡ºï¼‰

  ```shell
  docker run --gpus all --name FeatGraph-test -itd -v ~/ATC24/FeatGraph:/FeatGraph test/featgraph-sc20:v1.1 /bin/bash
  ```

+ æ‰“åŒ…å®¹å™¨è¿‡æ¥çš„é•œåƒï¼Œå†æ–°å»ºå®¹å™¨è¿›å»ï¼Œå®¹æ˜“æ²¡æœ‰nvcc -Vï¼Œéœ€è¦æ‰‹åŠ¨exportä¸€ä¸‹

  ```shell
  export LD_LIBRARY_PATH=/usr/local/cuda/lib
  export PATH=$PATH:/usr/local/cuda/bin

### é‡å¼€2 - Faith-ATC22

+ æ‰§è¡Œ`sh conda/build_cuda.sh`ä»ç„¶æœ‰ä¸Šè¿°é—®é¢˜ï¼ŒæŠ¥é”™ä¿æŒä¸€è‡´ï¼›ä½†**æŠ¥é”™æˆªå›¾**å¾—ä¸å¯¹ --- å¯ä»¥å®šä½åˆ°build cu102-tvmä¸Šæ¥

  + æŠŠcuda10.2çš„åˆ†æ”¯2å®‰è£…äº†å³`cuda_10.2.2_linux.run` ï¼›æ²¡æœ‰è§£å†³cmakeçš„é—®é¢˜
  + æ³¨æ„åˆ°éœ€è¦å®‰è£…cudnnï¼Œè¡¥å……å®‰è£…[cudnn8ï¼ˆcuda10.2å¯¹åº”ï¼‰](https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#verify); é‡æ–°ä½¿ç”¨[.tarçš„æ–¹å¼å®‰è£…](https://blog.csdn.net/h3c4lenovo/article/details/119003405)ï¼ˆå¦åˆ™æ²¡æœ‰ cudnn_version.h --- åœ¨makeæ—¶è§‚å¯Ÿåˆ°fatal errorä½†æ²¡ä¸­æ–­ï¼‰
  + æœ¬è·¯å¾„å°è¯•å¤šæ¬¡ï¼Œå¡ç‚¹ä¸ä»¥ä¸Šç›¸åŒï¼Œäºæ˜¯æ”¾å¼ƒ

### é‡å¼€2.2 - Faithä»å¤´å°è¯•

> æœ¬æ¬¡è§£å†³äº†æ¯ä¸€ä¸ªå°é”™å†å¾€ä¸‹èµ°

1. Ubuntuæ¢æºï¼Œpipæ¢æº
2. cuda10.2åˆ†æ”¯è¡¥å……å®‰è£…ï¼Œå§cudnnç­‰ä¿¡æ¯ç§»åˆ° /usr/local/cuda
3. Condaå®‰è£…å¹¶æ¢æº ----- ç›´åˆ°æ­¤æ­¥15min

+ `conda env create -f environment.yml` å‡ºç°æŠ¥é”™ï¼Œæœ‰6ä¸ªåŒ…æ²¡æœ‰å®‰è£…æˆåŠŸï¼›

  ```shell
  CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/anaconda/linux-64/libprotobuf-3.11.4-hd408876_0.tar.bz2>
  Elapsed: -
  
  An HTTP error occurred when trying to retrieve this URL.
  HTTP errors are often intermittent, and a simple retry will get you on your way.
  ```

  + è§£å†³æ€è·¯1: åœ¨æœ¬åœ°åˆ†åˆ«ä¸‹è½½å¥½äº†è¿™å‡ ä¸ª `*.tar.bz2` ä¸Šä¼ ä¸Šå»ï¼›åœ¨è¿œç«¯çš„`enviroment.yml`ä¸­åˆ å»å¯¹åº”çš„åŒ… - å…ˆåˆ›å»ºç¯å¢ƒAï¼Œè£…å…¶ä»–çš„ä¾èµ–ï¼›ç„¶åå†åœ¨condaç¯å¢ƒAä¸­ï¼Œæ‰‹åŠ¨ `conda install *.tar.bz2` 

    + `conda install ./tensorflow-base-1.14.0-gpu_py37h8f37b9b_0.tar.bz2`é”™è¯¯ æŠ¥äº†ä¸€ä¸²ç±»ä¼¼çš„

      ```shell
      CondaVerificationError: The package for tensorflow-base located at /root/anaconda3/pkgs/tensorflow-base-1.14.0-gpu_py37h8f37b9b_0
      appears to be corrupted. The path 'lib/python3.7/site-packages/tensorflow-1.14.0.dist-info/entry_points.txt'
      specified in the package manifest cannot be found.
      ```

      è§£å†³ï¼šåœ¨ `~/anaconda3/pkgs/` è·¯å¾„ä¸‹åˆ é™¤å¯¹åº”çš„åŒ…ï¼Œå†æ‰‹åŠ¨`conda install`å°±å¥½äº†

  + å®é™…è§£å†³ï¼šåœ¨å®‰è£…çš„æ—¶å€™`conda env create -f environment.yml` åˆ å»äº†å¯¹åº”çš„åŒ…ï¼Œè‡ªåŠ¨ä¸‹è½½äº†éœ€è¦çš„ä¸œè¥¿

    + è‡ªåŠ¨ä¸‹è½½ä¸è§£å‹çš„é”™è¯¯ï¼Œå…³äºOpenGLçš„ç›¸å…³é©±åŠ¨  --- è§£å†³ `apt-get install libgl1-mesa-dev`

      ```shell
      ERROR conda.core.link:_execute(698): An error occurred while installing package 'anaconda::pyopengl-3.1.1a1-py37_0'.
      Rolling back transaction: done
      
      LinkError: post-link script failed for package anaconda::pyopengl-3.1.1a1-py37_0
      location of failed script: /root/anaconda3/envs/NNver/bin/.pyopengl-post-link.sh
      ==> script messages <==
      <None>
      ==> script output <==
      stdout: Warning: Missing OpenGL driver, install with yum install mesa-libGL-devel or equivalent
      ```

+ å®Œå…¨éµç…§readmeæ‰§è¡Œï¼Œè§£å†³äº†æ¯ä¸€æ­¥ä¸­å°é”™è¯¯å†å¾€ä¸‹æ‰§è¡Œï¼Œï¼ˆä¹‹å‰æ²¡æœ‰å…³æ³¨è¿™äº›å°é”™ï¼Œä½†ä»ç„¶å¯ä»¥å¾€ä¸‹èµ°ï¼‰ã€‚ä¹‹å‰å…³äºmakeçš„å¡ç‚¹é—®é¢˜è§£å†³ï¼Œ`sh conda/build_cuda.sh`ï¼Œå³åœ¨è¿™é‡Œèƒ½å¤Ÿbuildåˆ°100% ï¼Œä½†æ˜¯å‡ºç°çš„æ–°çš„é—®é¢˜ä»ç„¶ä¸èƒ½äº§ç”Ÿæ–‡ä»¶tvm-cu102 

  <img src = 'https://s3.bmp.ovh/imgs/2023/11/09/88b57d8613bf876e.png' >

+ å†æ¬¡è¿è¡Œï¼Œå‘½åä¸ºFaith2.3ï¼Œä»ç„¶åŸºäºè¿™ä¸ªæµç¨‹ï¼Œä½†åœ¨å…¶é—´äº‹å…ˆè§£å†³äº†apt installçš„é—®é¢˜ï¼›æœ€åbuildæˆåŠŸ-100%ï¼Œä¸Faith2.2çš„é—®é¢˜ç›¸åŒï¼›ä½†æ˜¯å‡ºç°çš„æ–°çš„é—®é¢˜ä»ç„¶ä¸èƒ½äº§ç”Ÿæ–‡ä»¶tvm-cu102 ï¼›
  + é€šè¿‡è§‚å¯Ÿæ–‡ä»¶è¾“å‡ºï¼Œè®¤ä¸ºæœ‰å¯èƒ½æ˜¯é—®é¢˜å‡ºåœ¨llvmä¸Šï¼Œæ²¡æœ‰äº‹å…ˆå®‰è£…ï¼›ä½†LLvmçš„å®‰è£…è„šæœ¬å¹¶ä¸æ”¯æŒæ­¤é•œåƒubuntu16äº†
  + Faith2.3 åœå·¥ï¼Œä¸Faithå‡ºçš„é—®é¢˜ä¸€è‡´ï¼Œä½œä¸ºå®éªŒç»„ ---- ä¹‹åé€šè¿‡æºç ç›´æ¥å®‰è£…ï¼ˆä¹Ÿéœ€è¦LLVMï¼Ÿï¼‰è¯•è¯•çœ‹

###  é‡å¼€3 - Faith tvmæºç build

> åˆ›å»ºä¸€ä¸ª æ¯”è¾ƒåŸºç¡€çš„ä¸ªäººé•œåƒ ubuntu20 + cuda102
>
> å…¶ä½™çš„æ“ä½œåŒFaith2.3 æŠŠaptç­‰å®‰è£…åœ¨é—®é¢˜å‘ç”Ÿä»¥å‰

+ åœ¨ubuntu20 + cuda102 çš„dockerä¸­èµ°å…¨æµç¨‹conda-buildï¼Œè¿›å…¥å¡ç‚¹1 -- 99%å¤„ï¼ˆè¿˜ä¸å¦‚cuda10.2 + ubuntu16ï¼‰

+ å¸¸å‡ºç°çš„å°é—®é¢˜è§£å†³ `apt-get install --reinstall ca-certificates` 

```shell
Err:6 https://mirrors.tuna.tsinghua.edu.cn/llvm-apt/focal llvm-toolchain-focal-17 Release
  Certificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate.  Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]
```

#### condaç¯å¢ƒä¸­å®‰è£…tvmã€llvmçš„è·¯å¾„é—®é¢˜

+ æºç å®‰è£…tvmå‰ï¼Œä»ç„¶é¦–å…ˆè¿›è¡Œllvmå®‰è£…ï¼Œç„¶åæŸ¥çœ‹å®‰è£…æ˜¯å¦æˆåŠŸã€ç‰ˆæœ¬`llvm-as --version`
+ å°½ç®¡ æœ‰è¾“å‡ºï¼Œä½†æ˜¯ä»ç„¶åœ¨åé¢æ‰¾ä¸åˆ° `llvm-config`ï¼›
+ é€šè¿‡æŸ¥è¯¢ `which llvm-config`å‘ç°ï¼Œå’Œæˆ‘æ­£åœ¨ä½¿ç”¨çš„condaç¯å¢ƒæœ‰å…³ç³» ï¼Œllvm-configä½ç½®
  + æˆ‘çš„æ˜¯åœ¨`/root/anaconda3/envs/tvm-build/bin/llvm-config` --- **å†æ¬¡ç†è§£conda1**
  + è€Œä»¥å‰åœ¨écondaçš„å®‰è£…ç¯å¢ƒä¸­æ˜¯åœ¨  `/usr/bin/llvm-config`
+ äºæ˜¯é€šè¿‡åœ¨`config.make` ç›´æ¥**æŒ‡å®šè·¯å¾„** `set(USE_LLVM /path/to/your/llvm/bin/llvm-config)`é€šè¿‡æºç å®‰è£…TVMï¼ˆæœ€æ–°ç‰ˆ 0.14ï¼‰ä¸LLVM-14 æˆåŠŸ

#### Condaçš„pythonæ‰§è¡Œçš„æ—¶å€™æ‰¾ä¸åˆ°torch

+ åœ¨condaç¯å¢ƒ tvm-buildä¸­ï¼Œä½¿ç”¨`conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=10.2 -c pytorch` ä½†åœ¨pythonæ‰§è¡Œçš„æ—¶å€™æ‰¾ä¸åˆ°torch
+ ç»è¿‡which pythonæŸ¥è¯¢ï¼Œå‘ç°æ˜¯condaè£…çš„åŒ…å’Œæˆ‘å½“å‰çš„pythonè§£é‡Šå™¨è·¯å¾„ä¸ä¸€è‡´é€ æˆçš„
  + which pythonç»“æœ `/root/anaconda3/bin/python`
  + ä½†æˆ‘å½“å‰çš„å®‰è£…è·¯å¾„çš„pythonä¸º `/root/anaconda3/envs/tvm-build/bin/python3.7`
  + æ ¹æœ¬åŸå› ï¼š**å†æ¬¡ç†è§£conda2**ï¼Œcondaæ¿€æ´»äº†æŸä¸ªç¯å¢ƒï¼Œpythonè§£é‡Šå™¨ä¸ä¸€å®šåˆ‡æ¢è¿›æ¥äº†
+ éœ€è¦[å¼ºåˆ¶åˆ‡æ¢pythonè§£é‡Šå™¨](https://blog.csdn.net/qq_43744723/article/details/122090500)ï¼Œå’Œåˆ‡æ¢gccç¼–è¯‘å™¨çš„æ–¹æ³•éå¸¸ç±»ä¼¼ï¼›åˆ‡æ¢åæˆåŠŸ

#### åœ¨è¿œç«¯çš„dockerä¸­ä½¿ç”¨Jupyter notebook

+ `python matmul_ansor_benchmark.py`ä¸`python pytorch_benchmark.py --dir model --data yelp`æŠŠæŠ¥é”™æ’å®Œä»¥åï¼Œæ²¡ååº”ï¼Œæ²¡æœ‰è¾“å‡ºä¹Ÿæ²¡æœ‰ç»ˆæ­¢ ----åªæœ‰å‡½æ•°å®šä¹‰def

<img src = 'https://s3.bmp.ovh/imgs/2023/11/12/9bd4b5f5700148f1.png' >

+ åœ¨dockerä¸­[ç”¨jupyter](https://blog.csdn.net/fs1341825137/article/details/109683965)æ¥è¯•è¯•çœ‹æœ‰æ²¡æœ‰è¾“å‡º ---  æ¶‰åŠåˆ°ç«¯å£çš„æ˜ å°„ï¼Œæœ€å¿«çš„æ–¹å¼å…ˆæ‰“åŒ…ä¸ºé•œåƒå†å¯åŠ¨å®¹å™¨ 

  + å®¹å™¨å¯åŠ¨æ—¶ç»‘å®šç«¯å£ï¼ŒæŠŠdockerå†…çš„ç«¯å£æ˜ å°„åˆ°hostä¸Šï¼ˆåŒä¸€ç«¯å£å·ï¼‰ å¯åŠ¨`jupyter notebook` --- å†é€šè¿‡ æµè§ˆå™¨è®¿é—® `10.18.19.43:8080` 

    ```shell
    docker run --gpus all --name Faith3.1 -p 8080:8080 -itd -v ~/ATC24/Faith:/Faith ubuntu20-cu102/faith:v3 /bin/bash
    ```

  + åœ¨é‡æ–°å¯åŠ¨å®¹å™¨æ—¶ï¼Œå³ `source ~/.bashrc`æ—¶ï¼Œpythonåˆæ‰äº†ï¼›`which python`å‘ç°åˆåˆ‡äº†å›å»`/root/anaconda3/bin/python`ï¼›äºæ˜¯å¼ºè¡Œé€šè¿‡`ln -s` æŠŠ`/root/anaconda3/envs/tvm-build/bin/python3.7`é“¾åˆ°pythonä¸Šå»

#### cutlassè·¯å¾„æ‰¾ä¸åˆ°

```shell
(base) root@ae106e5d879f:/Faith/artifact# In file included from matmul_verification_artifact1.cu:16:0:
../tvm_kernels/cuda_kernel/mma/mma_kernel.h:1:10: fatal error: cutlass/cutlass.h: No such file or directory
 #include "cutlass/cutlass.h"
```

+ å»[Github/nvidia/cutlass](https://github.com/NVIDIA/cutlass/blob/main/media/docs/quickstart.md)å‚è€ƒè¯´æ˜å®‰è£…äº†cutlassï¼Œä½†å¹¶ä¸ç›´æ¥è§£å†³ä»¥ä¸ŠæŠ¥é”™ï¼›
  + ubuntuçš„Cè¯­è¨€ç¼–è¯‘ï¼Œincludeçš„æ–‡ä»¶åœ¨`/usr/include/` æˆ–è€… `/usr/local/include`
  + å°†cutlass2.6.0(æœ€åä¸€ä¸ªæ”¯æŒcuda10.2çš„ç‰ˆæœ¬)çš„æºç ä¸‹è½½ä¸‹æ¥åï¼Œå•ç‹¬æŠŠå…¶ä¸­çš„[include/cutlass/...](https://github.com/NVIDIA/cutlass/tree/main/include/cutlass)æ–‡ä»¶æ‹¿å‡ºæ¥ï¼Œæ”¾åœ¨ `/usr/local/include`ä¸‹ï¼Œè§£è§£å†³ä»¥ä¸ŠæŠ¥é”™

  

#### Faithè¿‡ç¨‹çš„ç»“è®º

+ æ„Ÿè§‰è¿™ä¸ªå·¥ä½œçš„ä»£ç å¼€æºå°±å±äºæ¯”è¾ƒä¸æ€æ ·çš„ï¼šï¼ˆ1ï¼‰å„ç§è·¯å¾„ä¸ç»Ÿä¸€ï¼ˆ2ï¼‰readmeä¸­å…³äºcondaçš„æ‰§è¡Œé€»è¾‘ä¸æ¸…æ¥šï¼ˆ3ï¼‰ç‰ˆæœ¬é™åˆ¶ä¸æ˜ï¼ˆ4ï¼‰é‡Œé¢ä¸€äº›ä¸ç¡¬ä»¶æœ‰å…³çš„ç¼–è¯‘å‚æ•°å†™æ­»ï¼ˆ5ï¼‰å®‰è£…çš„åº“ä¸å®Œå…¨(cloudpickle \ XGboost)
+ `Benchmark/*.ipynb`è·‘é€šï¼›ä½†æ˜¯ç”»å›¾çš„æ•°æ®æ²¡æœ‰å®Œå…¨è·‘å‡º  --- å…ˆç ”ç©¶å†è¯´




## å¤§å¡ç‚¹è®°å½•ï¼š

Faith: 

1. conda-buildä¸é€šï¼šå…ˆcondaå®‰è£…ä¾èµ–ï¼Œå†æºç å®‰è£…tvm

2. python benchmark. pyè¿è¡Œæ²¡ååº” ï¼šä½¿ç”¨jupyterå†å°è¯•

   

## å¤ç°å°ç»“  

+ å½“åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„docker

  + --gpuç»‘å®šé©±åŠ¨ã€--nameå‘½åã€--itdæ”¾åœ¨åå°è·‘ã€-p ç«¯å£æ˜ å°„ã€-væ–‡ä»¶å¤¹æŒ‚è½½
  + æ£€æŸ¥nvidia-smi\nvcc -Væ˜¯å¦å¯ç”¨ã€æ£€æŸ¥æ–‡ä»¶æŒ‚è½½æ˜¯å¦æˆåŠŸ
  + Ubuntuæ¢æºï¼Œpipæ¢æº
+ æ¬²é€Ÿåˆ™ä¸è¾¾ï¼Œè·‘åˆ°æœ€è¿œçš„ç¯å¢ƒç›´æ¥æ‰“åŒ…ä¸Šå¦ä¸€ä¸ªå¹³å°æ‰æ˜¯æœ€â€œå¿«é€Ÿâ€çš„æ‰‹æ®µ
+ å¯¹äºcmakeã€makeç­‰çš„é”™è¯¯ï¼Œé€šè¿‡æŠ¥é”™ä¿¡æ¯ä¸èƒ½ç«‹å³å®šä½åˆ°é”™è¯¯æ ¹æºï¼Œåº”è¯¥å›æº¯å…¨ç¨‹
+ condaçš„ä½œç”¨ä¸å±€é™äºpipåŒ…çš„é›†ä¸­ç®¡ç†ï¼Œæ›´åœ¨äºpythonè§£é‡Šå™¨çš„å¿«é€Ÿåˆ‡æ¢ã€llvmç¼–è¯‘å™¨çš„éš”ç¦»



# 2 - è‡ªä¸»æ¡†æ¶æ­å»º - æ‘¸æ–¹æ³•

| æ–‡ä»¶å         | å®ç°ç›®æ ‡                                                     | å¤‡æ³¨                                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| demo1          | åˆæ­¥å®ç°pytorchå¯¹cudaçš„è°ƒç”¨ï¼šos.system()çš„å½¢å¼è°ƒç”¨/ loadçš„å½¢å¼ | æ²¡æœ‰ä¼ å‚å‡ºæ¥ ã€æ‰‹åŠ¨ç®¡ç†å†…å­˜                                  |
| demo2          | æ¨¡ä»¿MLSys22 å®ç° ç®€å•çš„cudaç‰ˆ tensor_addæ“ä½œ                 | æœ‰ä¼ å‚æ•°å‡ºå…¥ ã€**è‡ªåŠ¨**ç®¡ç†å†…å­˜ --- ç¬¬ä¸€ä¸ªç†æƒ³çš„å•å…ƒ         |
| demo3          | demo2ä¸Šå¼ºåº¦ï¼Œå®ç°GEMM                                        | demo2 é‡å˜ã€CUDAä¸“å®¶çŸ¥è¯†ä¸Šå¼ºåº¦ï¼›å¼•å…¥è®¡æ—¶ã€Memç»Ÿè®¡**ï¼ˆCUDAçŸ¥è¯†å¤ä¹ ï¼‰** |
| microbenchmark | å¯¹Transformerç±»æ¨¡å‹çš„æµ‹è¯„æ–¹æ³•äº†è§£                            | ä½¿ç”¨huggingfaceçš„ç°æˆæ¨¡å—å‚æ•°è®¾ç½® `config.()`- ä¸»è¦å‚è€ƒææ²  |
| demo4          | demo3æ”¹å˜çŸ©é˜µè§„æ¨¡ï¼šéä»¿çœŸã€æ‰¹é‡çŸ©é˜µ---bmm                    | 1.09å›å­¦æ ¡çš„å¤å¥ ï¼›ä¼˜åŒ–è®¡æ—¶æ—¶é—´                              |
|                |                                                              |                                                              |
| demo4          | attention forwardè¿‡ç¨‹çš„ç®—å­æ›¿æ¢ å®ç°                         |                                                              |

## 2.0 é—®é¢˜æ’æ›² 

### 2.0.1 VScodeä»£ç é«˜äº®

```python
The Pylance extension is not installed but the python.language Server value is set to "pylance". Wouldyou like to install the Pylance extension to use Pylance, orrevert back to Jedi?
```

åŸæ¥æ˜¯VScodeé€‰çš„ä¸»é¢˜ä¸å¯¹ï¼Œ`command + shift + p`è®¾ç½®ä¸»é¢˜ä¸º`morden dark`è§£å†³

### 2.0.2 Gitå‡ºç°é—®é¢˜

å¤„ç†gitçš„æ—¶å€™`git clone https://github.com/Tencent/TurboTransformers --recursive`æŠ¥é”™ 

```shell
Cloning into '/home/david/Documents/other_work/TurboTransformers/3rd/Catch2'...
fatal: unable to access 'https://github.com/catchorg/Catch2.git/': gnutls_handshake() failed: The TLS connection was non-properly terminated.
fatal: clone of 'https://github.com/catchorg/Catch2.git' into submodule path '/home/david/Documents/other_work/TurboTransformers/3rd/Catch2' failed
Failed to clone '3rd/Catch2'. Retry scheduled
```

å‚è€ƒhttps://blog.csdn.net/qq_42921511/article/details/120551306ï¼›ä¸è¦ç”¨sudoï¼Œè€Œæ˜¯ä½¿ç”¨

```shell
git config --global --unset http.proxy 
git config --global --unset https.proxy
```

å†gitå³è§£å†³é—®é¢˜



## 2.1 CUDA-torchè€¦åˆdemo

### 2.1.1 Pytorch-ExtensionåŸºæœ¬ä¿¡æ¯

> å‚è€ƒPPT12.18

+ è°ƒç”¨æ–¹å¼1ï¼šå‚»é€¼çš„è°ƒç”¨æ–¹å¼ os.system() ---- ä¸å¯¹
  + åœ¨å‘½ä»¤è¡Œä¸­æ‰“å° å­—ç¬¦ä¸²â€œnvcc xxxx.cu - o xxxxâ€ç„¶åå†æ‰“å°å­—ç¬¦ä¸²è¿è¡Œè¯¥ç¨‹åº
+ è°ƒç”¨æ–¹å¼2ï¼šhttps://pytorch.org/cppdocs/installing.html#visual-studio-extension
  + pytorchæä¾›äº†C++çš„æ–¹å¼ï¼Œå®Œå…¨è„±ç¦»äº†â€œpytorchâ€ï¼Œåªæ˜¯ä¸€ä¸ª ***C torchï¼Ÿ***

+ å‚è€ƒ MLSys22çš„å®ç°æ–¹å¼ï¼ŒåŒ…å¤¹ç»“æ„

  1. `end2end.py` æœ€å¤–å±‚çš„è„šæœ¬ `os.system()` æ‰§è¡Œ  

  2. `train_gatconv_our.py `  ï¼šGATConvåœ¨é‡Œé¢ä½œä¸ºä¸€ä¸ªå‡½æ•°ä½¿ç”¨

  3. `layer/gatconv_layer.py ` ï¼šGATConvçš„å‡½æ•°å®šä¹‰

     + from operators.fused_gat import **fused_gat_op**,fused_gat_stash_op,fused_gat_fusescatter

  4. `operaters / fused_gat.py` è¯¥æ–‡ä»¶ 

     + å®šä¹‰äº†åŒåçš„ï¼šâ­ï¸***fused_gat*** = load(name = "**fused_gat**"ï¼Œ....)  --- **ç¼–è¯‘çš„è¿‡ç¨‹ï¼Ÿ**
       + `fused_gat/fused_gat.cpp`
       + `fused_gat/fused_gat.cu`
     + å®šä¹‰ **fused_gat_op** (....):  ---- åˆå°è£…äº†ä¸€å±‚ cpp/cu
       + returnäº†ä¸€ä¸ª class - FusedGATFunction 
       + class FusedGATFunctionä¸­ä½¿ç”¨äº† fused_gat.cpp / fused_gat.cu ä¸­çš„å‡½æ•°ï¼š**fused_gat**.gat_forward() 
         + æ­¤å¤„çš„`fused_gat.gat_forward() `åº”è¯¥æ˜¯loadè¿›æ¥çš„é‚£ä¸ª åŒåæ–‡ä»¶

     

+ é—®é¢˜1ï¼šç¼–è¯‘å®Œæˆï¼ˆçœ‹æ ·å­æ˜¯ç¼–è¯‘å®Œæˆäº†ï¼‰ï¼Œä½†ä¸èƒ½è¿è¡Œ --- æŸ¥è¯¢çš„å¤šæ•°ç»“æœè¯´æ˜¯ç¯å¢ƒã€ç‰ˆæœ¬é—®é¢˜ï¼›ä½†å®é™…ä¸ŠåŸå› åœ¨äºæ²¡æœ‰å†™.cppæ–‡ä»¶

  + ![](https://s3.bmp.ovh/imgs/2023/12/18/a2d9af01eef7eb01.png)
  + è§£å†³ï¼šå‚è€ƒgithubä¸Šçš„issueï¼šhttps://github.com/pybind/pybind11/issues/2145ï¼›éœ€è¦å†™ä¸€ä¸ªä¸“é—¨çš„ä¸ â€œ.cuâ€**åŒå**çš„cppæ–‡ä»¶
    + ä¸€ä¸ª A.pyéœ€è¦é…åˆcudaä½¿ç”¨çš„è¯ï¼šéœ€è¦ .cu + .cpp ----  å¯¹äº.cppä¸­çš„å†™æ³•ï¼šå£°æ˜.cuä¸­çš„å‡½æ•°



### æ’æ›²1 å‚è€ƒèŒå“¥æ‰€å®ç°çš„ æ‹“å±•

1. åœ¨huggingfaceä¸­æ›¿æ¢äº†ä¸€ä¸ª æ¨¡å—ï¼ˆGEMMï¼‰ä¸ºè‡ªå·±çš„
2. pytorchå®˜æ–¹

   + PyTorchè‡ªå®šä¹‰æ‹“å±• https://pytorch.org/docs/master/notes/extending.htmlï¼›ä¾‹å­ä¸­æ‰©å±•äº† [`torch.nn`](https://pytorch.org/docs/master/nn.html#module-torch.nn), [`torch.autograd`](https://pytorch.org/docs/master/torch.html#module-torch.autograd), [`torch`](https://pytorch.org/docs/master/torch.html#module-torch)
     + å…¶ä¸­æœ‰ä¸å¯å¾®çš„éƒ¨åˆ†ã€ä¾èµ–äºépytorchçš„åº“ï¼›æ›´è¿‘ä¸€æ­¥å¾€ä¸‹Cæ‹“å±•
       +  å­ç±»åŒ–ï¼ˆè‡ªå®šä¹‰çš„ï¼‰å‡½æ•°ï¼Œéœ€è¦å®šä¹‰forward()ã€backward() ç®—å­
     + è‡ªå®šä¹‰ tensor-like/å°è£…äº†tensorçš„ç±»
     + å¯¹PyTorch APIè¿›è¡Œé‡è½½
   + ã€èŒå“¥å‚è€ƒã€‘å…³äº CUDAæ‰©å±•çš„ä»‹ç» https://pytorch.org/tutorials/advanced/cpp_extension.html
     + create PyTorch operators defined *out-of-source*
     + `torch.utils.cpp_extension`å°±æ˜¯æ¥è‡ªäºæ­¤https://pytorch.org/docs/master/cpp_extension.html
     + ä½•æ—¶éœ€è¦è¿™ä¹ˆæ‹“å±•ï¼šå¯¹æ€§èƒ½è¦æ±‚é«˜ï¼ˆcallå¾—é¢‘ç¹ å•æ¬¡callæˆæœ¬é«˜ï¼‰

3. è¯•è·‘ç»“æœ æœªæˆåŠŸ --- `python test_matmul.py ` å‡ºç°é—®é¢˜ ï¼šåŠ¨æ€åº“ç¼–è¯‘æœ‰é—®é¢˜ï¼ˆæœªæœåˆ°è§£å†³æ–¹æ¡ˆï¼‰

```shell 
ImportError: /home/david/.cache/torch_extensions/py310_cu121/matmul/matmul.so: undefined symbol: _Z33cublas_tensor_core_matmul_cuda_4dN2at6TensorES0_
```



### 2.1.2  Pytorch Extensionä¾‹å­

+ é‡è¦çš„å‚è€ƒ
  + [Pybind-Docï¼špythonå¦‚ä½•ä¸C++ç»‘å®š]( https://pytorch.org/docs/master/cpp_extension.html)
  + [ã€æ•™ç¨‹ã€‘ï¼špytorchå¦‚ä½•æ‹“å±• cpp/CUDA](https://pytorch.org/tutorials/advanced/cpp_extension.html)ï¼šåé¢çš„ä¿¡æ¯ã€é“¾æ¥å‡æ¥è‡ªäºæ­¤æ•™ç¨‹

å®é™…ä¸Šæ”¯æŒä¸¤ç§æ‹“å±•

+ setuptoolsï¼šAOT - ahead of timeï¼ˆèŒå“¥çš„ä»£ç ä¸­æ‰€æ¶‰åŠçš„éƒ¨åˆ† ï¼‰
  + `<torch/extensions.h>`åŒ…å«äº†æœ‰ï¼š

    + `<ATen/ATen.h>`ï¼šThe **ATen library**,  Tensorè®¡ç®—çš„APTï¼ŒåŒ…å«äº†æ•°æ®ç±»å‹
    + `<pybind11.h>`ï¼š[pybind11](https://github.com/pybind/pybind11),  Python ä¸ C++ ç›¸ç»‘å®šçš„å·¥å…·

  + åœ¨å½“å‰ç›®å½•ä¸‹ä¿æŒ 

    ```shell
    pytorch/
      lltm-extension/
        lltm.cpp
        setup.py
    ```

    ç¼–è¯‘è¯­å¥ä½¿ç”¨ï¼š`python setup.py install --uesr || exit 1 `

  + å¯¹æ¯”è„šæœ¬ä¸‹

+ [`torch.utils.cpp_extension.load()`](https://pytorch.org/docs/stable/cpp_extension.html#torch.utils.cpp_extension.load)ï¼šJIT - just in timeï¼ˆã€MLSys22ã€‘ï¼‰

  + æ„å»ºè¿‡ç¨‹
    1. åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•`/tmp/torch_extensions/lltm`
    2. å°†Ninjaæ„å»ºæ–‡ä»¶å‘é€åˆ°ä¸´æ—¶ç›®å½•ä¸­
    3. å°†æºæ–‡ä»¶ç¼–è¯‘æˆè¿› shared library
    4. å°†æ­¤shared libraryå¯¼å…¥ä¸ºPython moudle
  + æ„å»ºç»“è®ºä¸Šè€Œè¨€ï¼š**Python moudleçš„ä½¿ç”¨æ–¹å¼å’Œsetuptoolsæ„å»ºçš„æ˜¯å®Œå…¨ä¸€æ ·çš„**
  + æ³¨æ„ï¼Œå› ä¸ºç”¨äº†Ninjiaï¼Œæ‰€ä»¥ç¼–è¯‘æ˜¯å¢é‡çš„incrementalï¼Œå¦‚æœreload extensionæ—¶æ²¡æœ‰ä¿®æ”¹cppè¿™äº›ï¼Œé‚£ä¹ˆè¿‡ç¨‹ä¼šå¾ˆå¿«
  + JITçš„å½¢å¼ä¸­ï¼Œ.cppå’Œ.cuæ–‡ä»¶å¯ä»¥åŒåï¼Œä½†æ˜¯AOTçš„å°±ä¸è¡Œ

+ JITä¸­æ›´è¿‘ä¸€æ­¥ ä½¿ç”¨æ‰‹æ‰‹å†™CUDA

  1. å…ˆå†™ä¸€ä¸ªç±»ä¼¼ AOT é‚£ç§æ–¹å¼æ—¶çš„ cppæ–‡ä»¶ ï¼šæ­¤ä¸­å®šä¹‰äº†å‡½æ•° å¹¶ä¸”å…·æœ‰pybind11çš„ä½œç”¨
  2. cppä¸­çš„å‡½æ•°ä¹Ÿèµ·åˆ°äº†å£°æ˜ .cuä¸­çš„å‡½æ•°çš„ä½œç”¨

+ JITå®ä¾‹ - Tensor_addçš„æ“ä½œ

  + é—®é¢˜1ã€æœªè§£å†³ã€‘ï¼šå…³äº`demo2_script.py` åœ¨ç»è¿‡å¤šæ¬¡ä¿®æ”¹ä»¥ä»¥åï¼Œä¼¼ä¹**æ— æ³•ç¼–è¯‘**ï¼›é‡æ–°å†™äº†ä¸ªä¸ä¹‹å†…å®¹å®Œå…¨ä¸€æ ·æ–‡ä»¶ï¼ˆæ–‡ä»¶åä¸ä¸€æ ·ï¼‰`demo2_script_bak.py` é‡æ–°ç¼–è¯‘ï¼Œç¼–è¯‘åˆæˆåŠŸ --- ç„å­¦ã€‚    

  + é—®é¢˜2ï¼š**æ•°æ®ç±»å‹**ï¼šåœ¨æŒ‡å®šå¼ é‡çš„æ—¶å€™å°±å¿…é¡»ç¡®å®šä¸ºfloatç±»å‹ï¼›åŒæ—¶åœ¨ä¸ºç»“æœå¼€è¾Ÿç©ºé—´çš„æ—¶å€™ä¹Ÿå¿…é¡»ç¡®å®šç±»å‹ï¼›ç»“æœæ•°æ®ç±»å‹å¦‚æœæ˜¯å¤šä¸ªå¼ é‡çš„è¯åº”è¯¥æ˜¯`std::vector<torch::Tensor>`ï¼›åªè¿”å›ä¸€ä¸ªå¼ é‡åˆ™æ˜¯`torch::Tensor`

    ```c++
    auto options = torch::TensorOptions().dtype(torch::kFloat32).device(tensor1.device());
    auto result = torch::empty({d1, d2}, options);
    ```

  + é—®é¢˜3ï¼šæ•°æ®æ²¡æœ‰æ¬ä¸ŠGPU --- ä½†è¿™ä¸€æ­¥åœ¨MLSysçš„ä»£ç ä¸­å¹¶æ²¡æœ‰ä½“ç°ï¼Ÿ

    ```cpp
    //ç¡®ä¿åœ¨ä¼ é€’ç»™CUDAå†…æ ¸ä¹‹å‰ï¼ŒPyTorchå¼ é‡çš„æ•°æ®å·²ç»è¢«ç§»åˆ°GPUä¸Š
        tensor1 = tensor1.cuda();
        tensor2 = tensor2.cuda();
    ```








### 2.1.3 Pytorch Extensionä¸Šå‹åŠ›

+ Demo3 çš„ä¾‹å­ - Matrix Mul

  + ä½¿ç”¨pythonçš„ `time.time()`è¿›è¡Œè®¡æ—¶ - åŸºæœ¬æ€è·¯å’ŒCä¿æŒä¸€è‡´ï¼›

  + å¯¹GPUçš„æ˜¾å­˜ è®°å½•

    ```python
    GPUs = GPUtil.getGPUs()
    GPU_Memory = GPUs[0].memoryUsed   #æ­¤å¤„ä¹‹æ‰€ä»¥ä¸ºGPUs æ˜¾å¡éœ€è¦æ˜¯listï¼Œå“ªæ€•åªæœ‰ä¸€å¼ éƒ½åº”è¯¥æ˜¯GPUs[0]
    ```

> ä»è¿™ä¸€æ­¥å¼€å§‹å‘ç°ï¼Œé™¤äº†æŠ¥é”™éœ€è¦åŠæ—¶è®°å½•è§£å†³è¿‡ç¨‹å’Œåˆ†ææˆå› å¤–ï¼Œè¾ƒä¸ºæµç•…çš„è¿‡ç¨‹å°±ä¸åšå¤ªå¤šè®°å½•ï¼›ä»£ç ä¸­ä¹Ÿæœ‰ç›¸åº”çš„æ³¨é‡Šå¯ç”¨



### 2.1.4 torchä¸­çš„æ˜¾å­˜è®°å½•

ä½¿ç”¨GPUtilï¼Œè®°å½•çš„ä¼¼ä¹æ˜¯ ç›´æ¥è·å–çš„æ˜¾å­˜ä¿¡æ¯ï¼Œä¸åŒçš„æ–¹æ³•é—´æ˜¾å­˜ä¸€æ · ---- ä¸å¯¹

```python
import GPUtil

GPUs = GPUtil.getGPUs()#æ£€æŸ¥GPUæ˜¾å­˜å ç”¨
GPU_Memory = GPUs[0].memoryUsed   #æ­¤å¤„ä¹‹æ‰€ä»¥ä¸ºGPUs æ˜¾å¡éœ€è¦æ˜¯listï¼Œå“ªæ€•åªæœ‰ä¸€å¼ éƒ½åº”è¯¥æ˜¯GPUs[0]
..... ï¼ˆprogramï¼‰
print("Golden GPU Memory: %s MB"%GPU_Memory)
```



### 2.1.5 demoå†è¿è¡Œå‡ºé—®é¢˜

åŒæ ·çš„ä¸€æ®µç¨‹åºæˆ‘ç°åœ¨ç¼–è¯‘ä¸äº†ï¼Œï¼ˆé™¤éæ˜¯ä»¥å‰ç¼–è¯‘ç”Ÿæˆè¿‡äº†å¯¹åº”çš„æ–‡ä»¶ï¼Œ**æ­¤æ¬¡**æ²¡æœ‰æ–°ç¼–è¯‘ï¼Œç›´æ¥ç”¨çš„.soæ–‡ä»¶ï¼‰ï¼Œå‡ºç°é—®é¢˜å¦‚ä¸‹

```shel
/local/lib/python3.10/site-packages/torch/include/pybind11/cast.h:%2520In%2520function%2520â€˜typename%2520pybind11::detail::type_caster<typename%2520pybind11::detail::intrinsic_type<T>::type>::cast_op_type<T>%2520pybind11::detail::cast_op(make_caster<T>&)â€™:
```

**è§£å†³**ï¼šé™ä½gccçš„ç‰ˆæœ¬ï¼ˆç”±äºç°åœ¨å®‰è£…çš„æ˜¯gcc12 --- `CUDA12.1` å®‰è£…çš„æ—¶å€™æ‰€è¦æ±‚çš„å‡çº§ï¼‰

+ ç¼–è¯‘è¿™ä¸ªè¿˜æ˜¯éœ€è¦é™å›`gcc11/g++11`ï¼Œè¿™ä¸¤è€…çš„ç‰ˆæœ¬åŠ¡å¿…è¦åŒ¹é…ï¼›å¦åˆ™ä¹Ÿæœ‰é—®é¢˜

  ```shell
  sudo update-alternatives --config gcc
  sudo update-alternatives --config g++
  ```

  

## 2.2 CUDA-torchå®ç°

å®ç°ç›®æ ‡ï¼šä¸€ä¸ªæ ‡å‡†çš„Transformerä½†ä½¿ç”¨æˆ‘ä»¬çš„ç®—å­åˆæ­¥è¿›è¡Œæ›¿æ¢

+ å‰ç½®çŸ¥è¯†

  1. æ ‡å‡†çš„Transformerï¼ˆPytorchï¼‰å…³æ³¨inferenceè¿‡ç¨‹ ä»£ç åœ¨å“ªé‡Œæ‰¾ï¼Ÿé•¿ä»€ä¹ˆæ ·ï¼Ÿ

     å‚è€ƒD2Lã€[ææ²è§†é¢‘ - æ³¨æ„åŠ›æœºåˆ¶](ã€64 æ³¨æ„åŠ›æœºåˆ¶ã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ v2ã€‘ã€‘ https://www.bilibili.com/video/BV1264y1i7R1/?share_source=copy_web&vd_source=fc58db99551d5dde52430792ddbb9243)

  2. æ€§èƒ½æŒ‡æ ‡çš„ç†è§£ - è®¡æ—¶æ–¹å¼å’Œå…·ä½“æ“ä½œæ˜¯å¦åˆç† - MLSys22çš„æ–¹å¼ä¹Ÿèƒ½ç…§æ¬ä½†ä¸å¤ªç†è§£

     è¿™ä¸€æ­¥è½¬å…¥äº†2-LearnNote



### 2.2.1 æ›¿æ¢torch.bmm()

```python
scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d) 
self.attention_weights = masked_softmax(scores, valid_lens)
return torch.bmm(self.dropout(self.attention_weights), values)
```

å…¶ä¸­æ•°æ®çš„ç»´åº¦ä¸º`queries:torch.Size([256, 10, 8]) keys.transpose(1,2):torch.Size([256, 8, 10]) values:torch.Size([256, 10, 8]) `

å¸Œæœ›æ›¿æ¢ä¸ºä¸‹é¢ï¼Œä½†æ˜¾ç„¶ç»´åº¦å¯¹ä¸ä¸Š

```python
scores = matrix_mul.run_matrix_mul(queries, keys.transpose(1,2))  / math.sqrt(d) 
self.attention_weights = masked_softmax(scores, valid_lens)
return matrix_mul.run_matrix_mul(self.dropout(self.attention_weights), values)
```

+ å¯¹æ¯”`torch.bmm` / `torch.dot` / `@`/`torch.matmul` 
  + `torch.bmm` ç”¨äºæ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼Œ
    + é€‚ç”¨äºæ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼ˆ**Batch** Matrix-Matrix Multiplicationï¼‰ã€‚è¾“å…¥å¼ é‡çš„å½¢çŠ¶åº”è¯¥æ˜¯ `(batch_size, n, m)` å’Œ `(batch_size, m, p)`ï¼Œè¾“å‡ºå½¢çŠ¶æ˜¯ `(batch_size, n, p)`ã€‚æ¯ä¸ª `n x m` çš„çŸ©é˜µéƒ½ä¸å¯¹åº”ä½ç½®ä¸Šçš„ `m x p` çŸ©é˜µç›¸ä¹˜ã€‚
  + `torch.dot` ç”¨äºä¸€ç»´å¼ é‡çš„ç‚¹ç§¯
  + `@` è¿ç®—ç¬¦å’Œ `torch.matmul` ç”¨äºä¸€èˆ¬çš„çŸ©é˜µä¹˜æ³•ï¼Œ
  + å…¶ä¸­ `torch.matmul` æä¾›æ›´å¤šçš„çµæ´»æ€§



## 2.3 æµ‹è¯•åŸºå‡†FasterTransformer

+ ä¾ç…§ Nvidiaå®˜æ–¹çš„githubè¿›è¡Œdockerå®‰è£…https://github.com/NVIDIA/FasterTransformer/blob/main/docs/bert_guide.md#requirements

  + æˆ‘çš„è®¾å¤‡4080laptopï¼Œæ‰€ä»¥å¯¹åº”çš„ Compute Capatity sm_89
  + åœ¨æœ¬æ¬¡å°è¯•ä¸­ ä½¿ç”¨dockeræ¥ä½œä¸ºè¿è¡Œç¯å¢ƒï¼Œæ–‡ä»¶è·¯å¾„æŒ‚è½½åˆ°å®¿ä¸»ä¸Šï¼Œæ‰€ä»¥å®é™…ä½¿ç”¨VScodeæ¥æ“ä½œ

+ ```
  #æ‹‰ä¸€ä¸ªdockerä¸‹æ¥ï¼Œnvå®˜æ–¹æä¾›é•œåƒï¼Œå¤§å°16GB CUDA 11.8  ubuntuç‰ˆæœ¬ä¸º22.04
  docker run --gpus all --name FasterTransformer -itd -v /home/david/Documents/other_work/FasterTransformer:/FasterTransformer nvcr.io/nvidia/pytorch:22.09-py3 /bin/bash
  ```

  + éœ€è¦åœ¨`/FasterTransformer/FasterTransformer/build`ç›®å½•ä¸‹ï¼Œé€šè¿‡ æ‰§è¡Œ

  + ```python
    python ../examples/pytorch/bert/bert_example.py <batch_size> <layer_num> <sequence_length> <head_number> <size_per_head> <--data_type fp32/fp16/bf16> <--int8_mode 0/1/2/3> <--sparse> <--time>
    python ../examples/pytorch/bert/bert_example.py 1 12 32 12 64 --data_type fp16 --time
    ```

æ•´ç†äº†ä¸€ä¸‹æ¯”è¾ƒå…³é”®çš„å‚æ•°

| å‚æ•°          | bert_example | bert_trans_test |      |      |
| ------------- | ------------ | --------------- | ---- | ---- |
| batch_size    | 1            | 16. (1)         |      |      |
| layer_num     | 12 ğŸ¤—         | 12              |      |      |
| seq_len       | 32 --- 64    | 64              |      |      |
| head_number   | 12ğŸ¤—          | 12              |      |      |
| size_per_head | 64ğŸ¤—          | 64              |      |      |
| avg_seq_len   |              | 32              |      |      |

å¤‡æ³¨ï¼š

hidden_size = hidden_dim

num_attention_heads=head_num

num_hidden_layers=layer_num



## 2.4 å«åœ æœŸæœ›æ‰¾å®˜æ–¹çš„ç‰ˆæœ¬

> 2.3 ä¸­çš„pytorchç‰ˆæœ¬çš„  FasterTransformer æ‰€å®ç°çš„å¯¹æ¯” æ„Ÿè§‰æ‘¸åˆ°äº†**å¯¹æ¯”**çš„å¤´ç»ª
>
> æ€»çš„æ¥è¯´æ‰¾çš„è¿™äº›ä»£ç å¯¹æ¯”èµ·æ¥æœ‰ä¸ªé—®é¢˜ï¼š**é¢å‘å¯¹è±¡ç¼–ç¨‹ --- éš¾ä»¥æ‹†ï¼ˆæ€•è®¡ç®—è¦ç´ ä¸å…¨ï¼‰**ä¸æ˜¯ä¾ç…§ç®—å­ç»„ç»‡çš„

### 1 - åšæŒæ‰¾pytorchå®˜æ–¹å®ç°

#### ï¼ˆ1ï¼‰ torch.nn.Transformer

+ **Doc** Encoderç»“æ„å®˜æ–¹å®ç° [Docs >torch.nn >TransformerEncoderç®—å­çš„ä»‹ç»]( https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html) ; ä½†è¿˜æ˜¯é¢å‘å¯¹è±¡ç¼–ç¨‹ã€æœ‰æºç 

  + åœ¨ä»–çš„ä¸Šä¸€å±‚è¿˜æœ‰[torch.nn.Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)ï¼› 

  + å±‚æ¬¡å…³ç³» torch.nn.modules.transformer < TransformerEncoder < TransformerEncoderLayer

    ```python
    transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)
    src = torch.rand((10, 32, 512))
    tgt = torch.rand((20, 32, 512))
    out = transformer_model(src, tgt)
    ```

  + ç¼ºç‚¹åœ¨åªæ˜¯**Doc** æ²¡æœ‰ä¸“é—¨åšå¯¹æ¯”çš„æ„Ÿè§‰ï¼Œä¸å¦‚æ‰¾åˆ«äººçš„å·¥ä½œç›´è§‚ --- æ²¡æœ‰æ›´å…·ä½“çš„ä¾‹å­

    ```python
    CLASS torch.nn.TransformerEncoder(encoder_layer, num_layers, norm=None, enable_nested_tensor=True, mask_check=True)
    ```

+ **Example**  https://pytorch.org/tutorials/intermediate/pipeline_tutorial.html ç›¸å¯¹å®Œæ•´ç‚¹ï¼Œç”¨äº†å®˜æ–¹çš„Encoder(ä¸Šé¢)ã€

  > ```python
  > from torch.nn import TransformerEncoder, TransformerEncoderLayer
  > ```

  + ä½†ä¸»è¦æ˜¯å¤šå¡çš„å¹¶è¡Œçš„ä¾‹å­
  + æ›´åŸºç¡€çš„å‚è€ƒâ­ï¸ [ä½¿ç”¨ Torchtext ä¸ nn.Transformerå®ç°çš„transformer_tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html?highlight=transformer%20encoder) è¿™ä¸ªä¾‹å­æ›´åå‘äºD2lé‚£ç§ï¼Œæ˜¯åŠŸèƒ½ä¸Šçš„å®ç°ï¼šï¼ˆ1ï¼‰å¯¹äºæ—¶é—´æµ‹è¯„ä¸æ¸…æ™°ï¼Œä¸æ˜¯æˆ‘æƒ³è¦çš„ï¼ˆ2ï¼‰ç¼–ç¨‹ä¸Šè¿‡äºé¢å‘åŠŸèƒ½è®¾è®¡ã€è¿˜åŸè®¾è®¡ç»“æ„ -- è¯­è¨€åŠŸèƒ½ï¼ˆ3ï¼‰è®­ç»ƒ+æ¨ç† æåˆ°ä¸€

#### ï¼ˆ2ï¼‰Pytorch Hubçš„å®ç° - Hgf

+ PyTorchçš„å®˜ç½‘ - èµ„æºResoureces/Models(Meta) --- [Pytorch Hub - å®Œå…¨äº¤ç»™äº†Hg](https://pytorch.org/hub/huggingface_pytorch-transformers/)
  + view on Githubåˆ™ä¼šç›´æ¥è·³è½¬ Hugface çš„ Githubç½‘é¡µï¼ˆå›åˆ°äº†Hgfaceï¼‰
  + FasterTransformerå€’æ˜¯ä¹Ÿå¯¹æ¯”äº†Hgfï¼Œä½†äººå®¶ä¸æ˜¯paperçš„å·¥ä½œï¼Œè€Œä¸”å‚æ•°è®¾ç½®æ²¡æ˜ç™½

#### ï¼ˆ3ï¼‰â­ï¸æœ€å¯è§‚çš„ä¾‹å­ - Attention 

+ ã€æœ‰æˆã€‘[é«˜æ€§èƒ½çš„Trasnformerå®ç° with Scaled Dot Product Attention ï¼šSDPA](https://pytorch.org/tutorials/intermediate/scaled_dot_product_attention_tutorial.html)ä¾‹å­å®ç°ï¼Œä¸»è¦æ˜¯å…³äºAttentionçš„ï¼Œæœ‰å®Œæ•´ä»£ç 

  + æ¶‰åŠåˆ°äº† Fusedçš„ QKVéƒ¨åˆ†

  + ç›®å‰åä¸º `torch.nn.functional.scaled_dot_product_attention` å·²ç»è¢«é›†æˆè¿› `torch.nn.MultiheadAttention` /`torch.nn.TransformerEncoderLayer` å³**ï¼ˆ1ï¼‰**

  + å¯¹äºç°åœ¨é›†æˆè¿› F.scaled_dot_product_attentionçš„æ“ä½œ å·²ç»æœ‰äº†ä¼˜åŒ– ï¼ˆä¸‹é¢ä¸‰è€…ä¹‹ä¸€ï¼‰

    + [FlashAttention](https://arxiv.org/abs/2205.14135)  / [Memory-Efficient Attention](https://github.com/facebookresearch/xformers) / Python ä¸€èˆ¬å®ç°çš„Attention

    ```python
    #å¯¹äºç°åœ¨é›†æˆè¿› F.scaled_dot_product_attention
    SDPBackend.MATH: {"enable_math": True, "enable_flash": False, "enable_mem_efficient": False},
    
    The default implementation runs in 4298.660 microseconds
    
    The math implementation runs in 22879.881 microseconds #æ— ä¼˜åŒ–çš„ç‰ˆæœ¬ -- math
    The flash attention implementation runs in 4329.078 microseconds #è¯æ˜ç°åœ¨pytorchç”¨çš„æ˜¯flash attention
    The memory efficient implementation runs in 4457.291 microseconds
    ```

  + **æ”¶è·ç‚¹ äº†è§£åšprofileçš„å·¥å…·ï¼Œ**ç„¶åç”¨ `chrome://tracing`æ‰“å¼€æ‰€ä¿å­˜çš„ `.json`æ–‡ä»¶

    ```python
    from torch.profiler import profile, record_function, ProfilerActivity
    ```

#### ï¼ˆ4ï¼‰Better Transformer

+ **Example** [FAST Transformer Inference with better Trasnformer](https://pytorch.org/tutorials/beginner/bettertransformer_tutorial.html#fast-transformer-inference-with-better-transformer)ï¼›

  + èƒ½ç”¨è¿™ç§æ–¹å¼åŠ é€Ÿçš„å‰ææ˜¯ï¼šå®ç°ä¸Šéƒ½åŸºäºäº†**ï¼ˆ1ï¼‰**ä¸­çš„é‚£äº›ï¼Œ æ‰€ä»¥**ç¼ºç‚¹å®Œå…¨ç»§æ‰¿**äº†

  + æ ·ä¾‹ä¸­åŸºäºäº† `torchtext.models`å·²ç»é¢„è®­ç»ƒå¥½äº†çš„æ¨¡å‹ï¼Œç›´æ¥import

    ```python
    import torch, torchtext
    from torchtext.models import RobertaClassificationHead
    
    xlmr_large = torchtext.models.XLMR_LARGE_ENCODER
    model = xlmr_large.get_model(head=classifier_head)
    #æµ‹è¯„æ—¶ --- æœ‰ç‚¹åƒ FasterTransformer æ‰€æ¼”ç¤ºçš„æ ·å­ï¼šåšæ¨ç†
    with torch.no_grad():
        for i in range(ITERATIONS = 10):
          output = model(model_input)
    ```

+ ç‰¹æ€§ä¸Šï¼šæ”¯æŒäº†ç¨€ç–---Exploiting **sparsity** in NLP inferenceï¼šæ¥è‡ªäºè¾“å…¥é•¿çŸ­ä¸ä¸€æ ·æ—¶å€™çš„ padding



### 2 - çœ‹åˆ«äººçš„å¯¹æ¯”æ¶ˆé™¤å¯¹.soçš„ææƒ§

| å·¥ä½œé¡¹ç›®                                                     | å¯¹æ¯”çš„                                                   | å¤‡æ³¨                                                         |
| ------------------------------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------------ |
| [FasterTransformer](https://github.com/NVIDIA/FasterTransformer) | ğŸ“Œ**å¯¹æ¯”æ˜ç¡®**hgfçš„ä¾‹å­ï¼›è‡ªå·±çš„ä¸¤çº§ä¼˜åŒ–                   | ä»è¿™ä¸ª[ä¾‹å­](https://github.com/NVIDIA/FasterTransformer/blob/main/examples/pytorch/bert/bert_example.py)ä¸­æ‘¸æ¸…äº† å¯¹æ¯”**è„šæœ¬å†™æ³•ã€æ•°æ®å‡†å¤‡ã€ä»£ç ç»„ç»‡ã€jit**ã€çƒ­èº«+100æ¬¡è¿­ä»£å¯¹æ¯”encoder ---âœ…å¯¹æ¯”æ—¶é—´ âœ…å’Œhgå¯¹æ¯” |
| [TurboTransformer](https://github.com/Tencent/TurboTransformers/)PPoPP21 | âŒ èåˆå¯ä»¥çœ‹ï¼Œä½†é¡¹ç›®æœ¬èº«ä¸å‚è€ƒ                           | é¡¹ç›®è¾ƒå¤§ï¼Œå¯ä»¥é€‰æ‹©çš„æ¨¡å‹å¾ˆå¤šï¼›ä½†å¯¹æ¯”çš„è¿‡ç¨‹ä»£ç ä¸æ¸…æ™°         |
| [ByteTransformer](https://github.com/bytedance/ByteTransformer)IPDPS23 | ä»£ç ä¸­**æ²¡æœ‰è¿›è¡Œå¯¹æ¯”** - åªæœ‰è‡ªå·±æ€ä¹ˆè·‘ã€ğŸ“Œ**æ­£ç¡®æ€§éªŒè¯** | æœ¬[ä¾‹å­](https://github.com/bytedance/ByteTransformer/blob/main/unit_test/python_scripts/bert_transformer_test.py)ä¸­çš„ä»£ç å‰å‘ç»“æ„ æ­£ç¡®æ€§åŸºå‡†æµ‹è¯•æ˜¯**é¢å‘è¿‡ç¨‹**ç¼–ç¨‹ï¼Œ**è®¡æ—¶æ˜ç¡®** âœ…å¯¹æ¯”æ­£ç¡®æ€§ |

+ å¯¹äºä¸€äº›æ¨¡å‹è®¾ç½®çš„åˆå§‹åŒ– è¿˜æ˜¯ä¼šå‚è€ƒ hgfğŸ¤— `import transformers`ç„¶åç”¨`BertConfig()\BertModel()`æ¥è®¾ç½®å‚æ•°

+ TurboTransformerå¯¹æ¯”è¿‡ç¨‹è¯¦è§£

  + [TurboTransformers](https://github.com/Tencent/TurboTransformers/tree/4532fa118c07375b3650f0768b70982c914be4ce)/[benchmark](https://github.com/Tencent/TurboTransformers/tree/4532fa118c07375b3650f0768b70982c914be4ce/benchmark)/ä¸‹ ï¼š benchmark.py é€‰æ‹©æ¡†æ¶torch--- >  torch_benchmark_helper.py é€‰æ‹©æ¨¡å‹Bert ---> benchmark_helper.py

    

### 3 - ä¸Šä»£ç è¯•è¯•

| è·‘é€š             | ä»£ç é¡¹ç›®    | ä¸»è¦ç›®çš„                                                     | å¤‡æ³¨                                                         |
| ---------------- | ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| åæ¥å‘ç°**é”™è¯¯** | benchmk1.py | æ‘¸æ¸…**å¯¹æ¯”æ—¶é—´**çš„æ–¹æ³•ã€å’Œ**åˆ«äººå¯¹æ¯”**çš„æ–¹æ³• --- ä¸»è¦å¯¹æ¯”äº†ğŸ¤—ï¼›æŠŠFasterTransformerçš„å¯¹æ¯”éƒ¨åˆ†æŠ½å–å‡ºæ¥ï¼Œå–hgfçš„åŸºå‡†ä¾‹å­<br />benchmk1.pyä¼¼ä¹æœ‰é”™è¯¯ï¼Œè®¡ç®—ä¸æ­£ç¡®ï¼›batch_sizeåªèƒ½ä¸º1 | å¯ä»¥é€‰ç”¨jitï¼šä¸å¼€5.78ms / å¼€3.3ms                            |
| âŒ æƒ³æ‹†å¼€ ä½†æ”¾å¼ƒ  | benchmk2.py | bhmk1.pyä¸­çš„åŸºå‡† æ‘˜å–æºç ï¼Œå¸Œæœ›ç»„ç»‡æˆ **é¢å‘è¿‡ç¨‹** ---- ç»„ç»‡è¿‡ç¨‹æ€•è®¡ç®—è¦ç´ ä¸å…¨ï¼Œå¯¼è‡´åŸºå‡†å°±æ˜¯é”™çš„ï¼ | æœ‰æºç  ä½†**é¢å‘å¯¹è±¡ç¼–ç¨‹**ï¼Œç®—å­æµç¨‹ä¸ç›´è§‚                    |
|                  | benchmk3.py | æ‘¸æ¸…å¯¹æ¯”æ­£ç¡®æ€§ï¼›æ¥è‡ªåœ¨ ByteTransformer                       | æ­£ç¡®æ€§éªŒè¯ æœ‰ä¸€ä¸ªå‰å‘çš„åŸºå‡†**(ç»“æœä¸æ­£ç¡®)**                  |
|                  | benchmk4.py | ä¿®æ­£benchmk1.pyçš„é—®é¢˜  é¡¶æ›¿1ç®—å‡ºæ¥çš„ä¸œè¥¿ç¡®ä¿æ­£ç¡®<br />ç¡®ä¿äº†**maskã€input**æ˜¯ä¸€è‡´çš„ | torch.jitåœ¨è¿™ä¸ªç‰ˆæœ¬çš„torchä¸­è·‘ä¸é€šï¼Œéœ€è¦åˆ°dockerä¸­ï¼ˆtorch = 1.13æ‰èƒ½ç”¨ï¼‰ ä¸¤ç§æ–¹å¼ç”Ÿæˆçš„**æƒé‡ä¸ä¸€è‡´** |



# 3 - åº•å±‚ä»£ç æ„å»º

æ­£å¼å¼€å§‹æ„å»ºè‡ªå·±çš„ä»£ç 

| ä»£ç é¡¹ç›®           | ä¸»è¦ç›®çš„                                                     | å¤‡æ³¨                                                         |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| base1.py           | æŠŠByteTransformerçš„ä¾‹å­ä¸­åŸºå‡†ä»£ç æŠ½å–å‡ºæ¥ï¼Œä½œä¸ºæˆ‘çš„**åŸºå‡†**  | åŠ ä¸Šäº†å¤‡æ³¨ï¼Œå’ŒFasterTransformerä¸­çš„æµç¨‹å›¾å¯¹é½ã€‚æ•°æ®çš„ç”Ÿæˆè¿˜æ˜¯éšæœºçš„ `uniform_(-0.4, 0.4)` |
| profile_sparity.py | æ¢ç´¢å…¶ä¸­çš„ç¨€ç–æ€§ï¼šéé›¶å…ƒæ•°é‡æ¯”ä¾‹ã€å…ƒç´ åˆ†å¸ƒã€å°äºæŸä¸€é˜ˆå€¼çš„æ•°é‡ï¼ˆä¸€ç›´æƒ³åšï¼Œä¸€ç›´ä¸çŸ¥é“å¦‚ä½•ä¸‹æ‰‹ï¼‰ | æ•°æ®ç”Ÿæˆéšæœºï¼Œè®¡ç®—æµç¨‹å’Œbase1ä¸­çš„ä¿æŒä¸€è‡´ --- ç¨€ç–æ€§çš„æ¢ç´¢ç»“æœå’Œå§æ…§å§çš„**ç»“è®ºä¿æŒä¸€è‡´** -- å‘ç°æ˜¯é‡å¤é€ äº†è½®å­ |
| base2.py           | ç”¨ä¹‹å‰çš„æ–¹æ³•æŠŠtorch.matmulæ›¿æ¢æˆæˆ‘è‡ªå·±çš„ç®—å­ï¼Œç”¨ä¹‹å‰çš„cudaæ–‡ä»¶**Load** | âŒå›°éš¾ï¼šæˆ‘è‡ªå·±å†™çš„run_matmulä¸ä¹‹ **ç»´åº¦å¯¹é½**                 |
| fuse.py            | æŠŠByteTransformerä¸­çš„ï¼ˆ.cu / .hï¼‰**èåˆä»£ç **åˆ‡å‡ºæ¥ï¼Œæ”¾åˆ°base1ä¸­åšä¸€å®šçš„æ›¿æ¢ - **å¸Œæœ›åŸºäºå®ƒ** | âŒå› ä¸ºå…¶ä¸­æ˜¯.cuä»£ç ï¼Œæ›¿æ¢è¿›å»ä¹Ÿéœ€è¦loadå·¥ä½œã€‚æ²¡æˆåŠŸåŸå› ï¼šâ‘ ä»–å®ç°çš„èåˆåªé’ˆå¯¹fp16 --- ç”¨äº†tensor-coreï¼›å„å¤„ç±»å‹å¯¹é½ä¸æ•¢ä¿è¯æ­£ç¡®æ€§ â‘¡åªæœ‰å®šä¹‰æ²¡æœ‰è°ƒç”¨å…³ç³»- CMakeä¸º.soçš„å½¢å¼ â‘¢èåˆåçš„ä»£ç ï¼Œå› ä¸ºæœ‰ç‰¹æ®Šä¼˜åŒ–zero-pad,å¾ˆå¤šç´¢å¼•çœ¼èŠ±ç¼­ä¹± |
| my_sdp.py          | ç”¨æˆ‘çš„åŸºå‡†å’Œ `F.scaled_dot_product_attentiond`å¯¹é½ç»“æœï¼Œæ¯”è¾ƒæ­£ç¡®æ€§ | Pytorch - `F.scaled_dot_product_attentiond`ä¸­å¯¹äºmask / scaleå€¼ä¹Ÿä¸ä¸€æ ·ï¼›è¶…å‚è§„æ¨¡å°æ—¶ï¼Œå¯ä»¥å¯¹ä¸Šï¼›è§„æ¨¡å¤§äº†ç²¾åº¦å·®å¼‚ä¼šæ‰©å¤§ |
| fuse1.pyğŸ“Œ          | å› ä¸ºfuseçš„å¤±è´¥ï¼Œè‡ªå·±æ„å»ºèåˆçš„MHAï¼Œæ”¾åˆ°base1ä¸­ ï¼Œä¸End Attentionä¹‹åçš„ éƒ¨åˆ†å¯¹é½è®¡ç®—ç»“æœ | éš¾ç‚¹ï¼šâ‘ ä¸base2ç›¸åŒ â‘¡ä¸­é—´æ¶‰åŠç»´åº¦å˜æ¢ ç´¢å¼•åº”çœ‹æ¸… â‘¢CUDAç¼–ç¨‹è€å¤§éš¾ï¼Œå¤šå¤šç†Ÿæ‚‰ -- - ä»»åŠ¡åˆ’åˆ†<br />æ¶‰åŠå¾ˆå¤šCUDAç¼–ç¨‹æ·±æ°´åŒº --- ç®—å­èåˆå°¤å…¶çœ‹é‡`shared Mem` |
|                    |                                                              |                                                              |

+ åœ¨fuse1.py çš„æ„å»ºè¿‡ç¨‹ä¸­ è€ƒè™‘è¦**åœæ‰‹**ï¼Œè¡¥å……ä¸¤æ–¹é¢çŸ¥è¯†
  1. CUDAç¼–ç¨‹ä¸“å®¶çŸ¥è¯† -- æ—¶é—´çº¿é•¿ã€æ·±åº¦å¤§ï¼Œä½†å€ŸåŠ©ä¸€äº›ä¾‹å­å†æ¬¡ä¸Šæ‰‹
  2. softmaxçš„å®ç°ï¼š[SoftMaxåŸºæœ¬æœºåˆ¶](https://www.zhihu.com/question/435368791) , åŸæ¥çš„ä»£ç ç©¶ç«Ÿåœ¨å“ªä¸ªç»´åº¦ä¸Šsoftmaxï¼ˆdim = -1ï¼‰âœ…
  
  ```shell
  #ç¼–è¯‘å®Œæˆï¼Œä½†å‡ºç°é—®é¢˜ ---- åŒèŒå“¥ä»£ç ä¸­çš„ä¸€è‡´ -- è²Œä¼¼æ˜¯å…¶ä¸­çš„ä¸€ä¸ªå‡½æ•°
  ImportError: /home/david/.cache/torch_extensions/py310_cu121/my_fused_attention/my_fused_attention.so: undefined symbol: _Z18run_batchMatrixMulN2at6TensorES0_
  ```
  
  è§£å†³é—®é¢˜ï¼š`.cu`ä¸`.cpp`ä¸­çš„å‡½æ•°å¹¶ä¸åŒ¹é… --- `run_my_fused_attentionï¼ˆï¼‰`åœ¨`.cu`ä¸­æœ‰ï¼Œä½†`.cpp`æ²¡æœ‰ï¼Œæ‰€ä»¥å‡ºé—®é¢˜
  
  

### sqrtæœªæ›¾æƒ³åˆ°çš„é—®é¢˜ 

åæ¥å‘ç°æ˜¯è‡ªå·±çš„æ•°æ®ç»´åº¦æ²¡æœ‰å¯¹é½

```python
#pythonä»£ç çš„ç¨‹åº
scores1 = torch.matmul(A.float(), B.float().transpose(-2, -1)) / (head_size ** .5)
#CUDA ä»£ç çš„ç¨‹åº --- è¿™ä¸ªsqrtçš„ç»“æœä¸head_sizeæœ‰å…³ç³»
score = score / sqrtf(static_cast<float>(head_size));
```



### q/kè¢« è¦†ç›– - äº¤æ¢ä½ç½®äº†

```shell
q :  tensor([[[[-0.0089,  -0.4835, 0.1279,  0.3058],
          [0.2417,  -0.2100,  0.1727,  0.2396],
          [0.1062,  -0.4100, 0.0001,   0.2044]]]], device='cuda:0')
k :  tensor([[[[ 0.0864, -0.0528,  0.0878,  0.4383],
          [-0.0909, -0.0006, -0.0388,  0.1715],
          [-0.0174, -0.1024,  0.1518,  0.2891]]]], device='cuda:0')
q( 0, 0): -0.008909 * k ( 0, 0):  0.086396
q( 1, 0):  0.086396 * k ( 0, 0):  0.086396
q( 2, 0):  0.624452 * k ( 0, 0):  0.086396
q( 0, 0): -0.008909 * k ( 0, 1):  0.624452
q( 1, 0):  0.086396 * k ( 0, 1):  0.624452
q( 2, 0):  0.624452 * k ( 0, 1):  0.624452
q( 0, 0): -0.008909 * k ( 0, 2):  0.241676
q( 1, 0):  0.086396 * k ( 0, 2):  0.241676
q( 2, 0):  0.624452 * k ( 0, 2):  0.241676
q( 0, 1): -0.483517 * k ( 1, 0): -0.052824
q( 1, 1): -0.052824 * k ( 1, 0): -0.052824
q( 2, 1): -0.265493 * k ( 1, 0): -0.052824
q( 0, 1): -0.483517 * k ( 1, 1): -0.265493
```

æ˜¾ç„¶å…¶ä¸­çš„ `q(1,0)ã€q(2ï¼Œ0)`è¢« kçš„æŸäº›å…ƒç´ ç»™è¦†ç›–æ‰äº†ï¼›è€Œ`k(0, 2)`åˆè¢«`q(1,0)`è¦†ç›–äº†



## 3.1 Fuse1 çš„å±•å¼€ debug

| æ–‡ä»¶å                                     | ç›®çš„                                                         | å¤‡æ³¨                                                         |
| ------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| fuse1.pyğŸ“Œ                                  | å› ä¸ºfuseçš„å¤±è´¥ï¼Œè‡ªå·±æ„å»ºèåˆçš„MHAï¼Œæ”¾åˆ°base1ä¸­ ï¼Œä¸End Attentionä¹‹åçš„ éƒ¨åˆ†å¯¹é½è®¡ç®—ç»“æœ | éš¾ç‚¹ï¼šâ‘ ä¸base2ç›¸åŒ â‘¡ä¸­é—´æ¶‰åŠç»´åº¦å˜æ¢ ç´¢å¼•åº”çœ‹æ¸… â‘¢CUDAç¼–ç¨‹è€å¤§éš¾ï¼Œå¤šå¤šç†Ÿæ‚‰ -- - ä»»åŠ¡åˆ’åˆ†<br />æ¶‰åŠå¾ˆå¤šCUDAç¼–ç¨‹æ·±æ°´åŒº --- ç®—å­èåˆå°¤å…¶çœ‹é‡`shared Mem` |
| fuse1_fix1.py                              | è¯•è·‘ä»£ç çš„ä¸€èˆ¬åŸºå‡† - QKTè®¡ç®—æ­£ç¡®                             | åªé’ˆå¯¹äº head_numã€batch_size = 1çš„æƒ…å†µ                      |
| fuse1_fix2.py                              | QK^T_mask_softmaxæ­£ç¡®                                        | åªé’ˆå¯¹äº head_numã€batch_size = 1çš„æƒ…å†µ / seq_len< 16ï¼›å…¶ä¸­å¿…é¡»head_size >= seq_len --- ä¸€èˆ¬head_size = 64ï¼› |
| fuse1_fix3.py -`fused_attention.cu0124`    | ä¸è¿½æ±‚Attentionçš„å…¨è¿‡ç¨‹ï¼›ä¿è¯`QK^T_mask_softmax`ï¼Œä¹‹åçš„*Vè¿‡ç¨‹è¿”å›åˆ°pythonä¸­ç®— | ç¡®ä¿seq_len > 16ä¸ <16âœ…çš„æƒ…å†µéƒ½èƒ½æ­£ç¡®<br />æŠŠseqçš„ä¸¤ç§å¤§å°åˆ†å¼€å†™ï¼›<=16çš„æƒ…å†µå†™ä½œä¸€ä¸ªç®—å­ï¼Œ> 16å†™æˆä¸¤ä¸ªç®—å­ï¼ˆçº¿ç¨‹è§„åˆ’å˜åŒ–ï¼‰ |
| fuse1_fix3.py - `fused_attention.cu0125-1` | â‘ batch_size å¯ä»¥ä¸ç­‰äº1ï¼Œåœ¨1 ï¼Œ8 ï¼Œ16 éƒ½å¯ä»¥æˆåŠŸ â‘¡head_num å¯ä»¥ä¸ç­‰äº1ï¼Œ åœ¨æµ‹è¯•æ—¶ä¸€èˆ¬è®¾ç½®ä¸º 12 | âœ…å……åˆ†ä½¿ç”¨ `q.storage_offset() &  q.stride()`                 |
| å›å½’fuse1.py - `fused_attention.cu0125- 2` | seq_len 16 -- 1024(æ€»æ˜¯8çš„å€æ•°) éƒ½ç»Ÿä¸€ä¸ºä¸€ä¸ªkernel --- ä»»åŠ¡è§„åˆ’ä¸€ä¸ªthreadå¤„ç†ä¸€è¡Œ(seq_len)ï¼ŒæŠŠGEMM2ä¹Ÿèåˆè¿›æ¥ | ä»»åŠ¡è§„åˆ’æ”¹ä¸ºäº† ä¸€ä¸ªthreadå¤„ç†ä¸€è¡Œï¼ˆå¯¹æ¯”å®éªŒ - æ•ˆæœå¾ˆå·®ï¼‰ğŸ¤¯    |



## 3.2 ä¸Šsyncfreeä¹‹åçš„æµ‹è¯•

> æ— åŒæ­¥ï¼šå’¨è¯¢é˜³å“¥ä»¥å - ä¸éœ€è¦ç­‰å¾…å¤šä¸ªkernelçš„å¯åŠ¨ï¼›æ›´å¤šæ˜¯ä¸€ç§è§£é‡Šä¸Šçš„ä¸œè¥¿

æ­¤æ—¶çš„ç»“è®ºæ˜¯ - åœ¨ä»£ç çš„æ„å»ºé˜¶æ®µï¼Œå¦‚æœæ–¹å‘é€æ¸æ¸…æ™°äº†ï¼›ä¸éœ€è¦å†™é‚£ä¹ˆå¤šä¸œè¥¿ - å¤ªèŠ±æ—¶é—´äº†



## 3.3 ncuä¸nsys åˆ†ækerenlæ€§èƒ½

+ `nsysï¼šNvidia Nsight Systems`ç²—ç²’åº¦åˆ†æ / `ncuï¼šNvidia Nsight Compute`ç»†ç²’åº¦åˆ†æ 

  + å‰è€…æ˜¯Sysçº§çš„ï¼Œä¸ä»…å¯¹GPUï¼Œè¿˜å¯¹CPU/IPä»¥åŠOSéƒ½æœ‰åˆ†æåˆ° --- å°±æ˜¯æ•°æ®æŒ‡æ ‡çœ‹çƒä¸æ‡‚ï½

+ ä¸¤è€…éƒ½æ˜¯å¯¹kenrelå±‚é¢çš„åˆ†æï¼ˆå“ªæ€•ä½ ç¼–è¯‘æˆäº†`.so`ï¼‰ï¼Œæ¯”å¦‚æˆ‘çš„ä»»åŠ¡ä¸­æ˜¯`python XXX.py`å…¶ä¸­è°ƒç”¨çš„cudaéƒ½èƒ½çœ‹åˆ°

  + å› ä¸ºæ˜¯ç›´æ¥å¯¹GPUåšçš„ç›‘æµ‹ï¼Œæ— è®ºä»¥ä»€ä¹ˆæ–¹å¼è¿è¡Œçš„ç¨‹åºï¼Œåªè¦ç”¨åˆ°çš„CUDA kernelè¢«æäº¤ç»™äº†GPUï¼Œé‚£ä¹ˆå°±éƒ½èƒ½çœ‹åˆ°
    + æ‰€ä»¥ä¸ä»…ä»…æ˜¯`nvcc sample.cu -o sample.out `ç”Ÿæˆæ‰§è¡Œçš„æ–‡ä»¶èƒ½ç”¨å‘½ä»¤`ncu sample.out`ç›‘æµ‹ï¼Œåƒæˆ‘çš„pythonè„šæœ¬ä¹Ÿå¯ä»¥ç”¨`ncu python sample.py`æ¥ç›‘æµ‹

+ ä½¿ç”¨ï¼šLinuxç›‘æµ‹ å’Œ æŸ¥çœ‹ åˆ†ç¦»

  + æœ¬åœ°éœ€è¦åœ¨[Nvidia Developer / CUDA compute]( https://developer.nvidia.com/tools-overview)ä¸­æŒ‰ç…§ä½ çš„æœ¬åœ°ç³»ç»Ÿæ¥ä¸‹è½½æŸ¥çœ‹è½¯ä»¶

  + é€šè¿‡å…ˆåœ¨å‘½ä»¤è¡Œä¸­ç”Ÿæˆå¯¹åº”çš„`.ncu-rep`æˆ–`.nsys-rep`ï¼›ç„¶åæ‹‰åˆ°æœ¬åœ°-ç”¨æŸ¥çœ‹è½¯ä»¶æ‰“å¼€

    ```shell
    #nsyçš„åˆ†ææ–¹æ³• - ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶åœ¨å½“å‰è·¯å¾„ä¸‹ï¼Œåä¸º XXX.nsys-rep
    nsys profile python syncfree1.py 8 1 256 12 64
    
    #ncuçš„åˆ†æ - å¯ä»¥åœ¨å‘½ä»¤è¡Œå°±æŸ¥çœ‹ ä¹Ÿå¯ä»¥ä¿å­˜ä¸ºæŠ¥å‘Š
    #åœ¨å‘½ä»¤è¡Œä¸­ç›´æ¥æŸ¥çœ‹ï¼›æ–¹ä¾¿ï¼Œä½†kernelä¸€å¤šè¾“å‡ºå°±å¾ˆéš¾æ¥å—äº†ï¼›ä¸éœ€è¦å¯¹åº”çš„æŸ¥çœ‹è½¯ä»¶
    ncu -o python syncfree1.py 8 1 256 12 64  
    #ç”ŸæˆæŠ¥å‘Šï¼Œåä¸º XXX.ncu-rep
    ncu -o rep1 python syncfree1.py 8 1 256 12 64
    ```


### åˆ†æå®ä¾‹ - æŒ‡æ ‡çš„è§£é‡Š

```shell
syncfree_triangle_attention_kernel(const float *, const float *, const float *, float *, int, int, int, int, int, int, int, int)
Begins: 4.11906s
Ends: 4.12081s (+1.749 ms)
grid:  <<<256, 8, 12>>>           #kernelçš„ä»»åŠ¡åˆ’åˆ†
block: <<<32, 1, 1>>>
Launch Type: Regular
Static Shared Memory: 136 bytes   #æ¯ä¸ªblockçš„å ç”¨ï¼Œæˆ‘åªæœ‰34ä¸ªfloat 34*4B=136B 
Dynamic Shared Memory: 0 bytes    #æˆ‘çš„ä»£ç ä¸­æ²¡æœ‰åŠ¨æ€çš„è¿™éƒ¨åˆ†è®¾ç½®---åœ¨<<<gridSize, blockSize>>>ä¸­æ²¡è®¾ç½®
Registers Per Thread: 37
Local Memory Per Thread: 0 bytes
Local Memory Total: 79,822,848 bytes
Shared Memory executed: 32,768 bytes
Shared Memory Bank Size: 4 B     
Theoretical occupancy: 50 %       #SMå ç”¨ç‡:ä¸€ä¸ªSMä¸­active warpsæ•°/æœ€å¤§å¯èƒ½çš„active warpsæ•°
Launched from thread: 48208
Latency: â†5.236 ms
Correlation ID: 745448
Stream: Default stream 7
```

+ å…³äºOccupancyå ç”¨ç‡çš„è§£é‡Š[çŸ¥ä¹ - GPUåŸºç¡€ï¼šOccupancyã€wave and tail effect](https://zhuanlan.zhihu.com/p/657005697)

  + **é«˜å ç”¨ç‡**ä¸æ€»æ˜¯ä»£è¡¨é«˜æ€§èƒ½ï¼›æ²¡é‚£ä¹ˆé«˜çš„æ—¶å€™ï¼Œå°±æ˜¯æœ‰é™çš„ä»»åŠ¡ï¼Œä½†èµ„æºå¾ˆä¸°å¯Œèƒ½å¹²å¥½ 
  + ä½†æ˜¯ï¼ˆè¿‡ï¼‰**ä½å ç”¨ç‡**æ€»æ˜¯ä¼šå¹²æ‰°éšè—å†…å­˜å»¶è¿Ÿçš„èƒ½åŠ›ï¼Œæ€§èƒ½ä¼šä¸‹é™
  + æ‰€ä»¥å­˜åœ¨ä¸€ä¸ªæœ€ä½³ç‚¹ï¼Œè¶…è¿‡è¿™ä¸ªç‚¹ä»¥å ï¼Œæé«˜å ç”¨ç‡ä¸ä¼šæé«˜æ€§èƒ½

  

  

## 3.4 ä¸“æ³¨äºææ€§èƒ½

> æ€»ä½“æ€§èƒ½ç›®æ ‡ï¼šæŠŠåŠ é€Ÿæ¯”å…¨éƒ¨æåˆ°1ä»¥ä¸Š
>
> è®ºæ–‡ä¸­ä¼šæœ‰ä¸»æ—¨çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä½†è¿™ç§æ–¹æ³•å¯èƒ½åªé€ æˆäº†20%çš„åŠ é€Ÿï¼Œå‰©ä¸‹80%çš„åŠ é€Ÿæ¥è‡ªäºä»£ç å®ç°ä¸Šçš„å°trick

1. `dim3 blockSizeDim(head_size/2)`ï¼Œwarpå†…å±•å¼€

   + ä¸€ä¸ªwarpå¹²2ä¸ªwarpçš„äº‹å‡å°åŒæ­¥æˆæœ¬; 

   + ä¸€åˆ‡`syncthreads()`æ›´æ¢ä¸ºæ›´è½»é‡çº§çš„`__syncwarp()` 

   + ä½¿ç”¨warpå†…çš„åŒæ­¥/å¹¿æ’­æœºåˆ¶ `shfl_xor_sync/shfl_sync`æ›¿ä»£åŸæ¥çš„éƒ¨åˆ†`__syncwarp()`åŒæ­¥

     (ç”±è€å¸ˆçš„æ— åŒæ­¥ä»£ç å¸¦æ¥çš„å¯ç¤º)  ä¸»è¦å‚è€ƒ[cuda-c-programming-guideå…³äºcuda-c-programming-guideçš„ä»‹ç»](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-shuffle-functions)

   + ä½¿ç”¨æŒ‡ä»¤`__ldg()`æ²¡å•¥æå‡ - [å¸¸é‡å†…å­˜ä¸çº¹ç†å†…å­˜ã€è¡¨é¢å†…å­˜ä½¿ç”¨](https://zhuanlan.zhihu.com/p/680075822)

     å¸•æ–¯å¡æ¶æ„åŠå…¶æ›´é«˜æ¶æ„é»˜è®¤ä½¿ç”¨ `__ldg()` å‡½æ•°è¯»å–å…¨å±€å†…å­˜ï¼Œæ•…ä¸éœ€è¦æ˜¾å¼ä½¿ç”¨

2. `dim3 blockSizeDim(head_size/2, head_num)`ï¼Œ

   + ä»ç„¶ä¿æŒwarpå†…å±•å¼€ï¼›ä½†åŒæ­¥åªåŒæ­¥warpå†…çš„çº¿ç¨‹ï¼›

   + å¯èƒ½æé«˜äº†SMçš„åˆ©ç”¨ç‡

     

3. æå–åˆ«çš„ä»£ç ä¸­çš„æŠ½è±¡æ€è·¯ï¼Œæ”¾è¿›æˆ‘çš„ä»£ç ä¸­ï¼›;ä¸»è¦å‚è€ƒä»£ç æ¥æº

+ å‚è€ƒæ–¹æ³•ï¼šå…ˆçœ‹çœ‹ä»£ç ç»„ç»‡æ¡†æ¶ ---> æ‰¾åˆ°æ ¸å¿ƒè„šæœ¬ ä¸ å®ç°Attentionçš„éƒ¨åˆ† ---> ä¸»çœ‹ä»£ç ï¼Œè®ºæ–‡ä¸ºè¾… 

+ ByteTransformer 

  + ä¼˜åŒ–ç‚¹

  + æ ¸å¿ƒä»£ç 

    `/other_work/ByteTransformer/unit_test/python_scripts/bert_transformer_test.py`

    `/other_work/ByteTransformer/bytetransformer/src` 

+ FlashAttention

+ FasterTransformer

+ TurboTransformer



# 4 - ä¸­å±‚ä»£ç æ„å»º

| æ–‡ä»¶å                   | ä¸»è¦ç›®æ ‡                                                     | å¤‡æ³¨                                                         |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1ï¸âƒ£generate_demo_single.py | ã€3.01ã€‘å¯¹äºå½“å‰0-14çš„ç®—å­å¯ä»¥éšæœºé€‰ä¸€æ®µæ¥è¿›è¡Œèåˆ - æ”¾è¿›ä¸€ä¸ªå‡½æ•°é‡ŒåŒ…èµ·æ¥ | â‘ å‡½æ•°çš„åå­—æå¾—æ›´ä¸“ä¸šä¸€äº› â‘¡`os.system` æ‰§è¡Œå°è¯• â‘¢æ°å¥½èåˆAttentionçš„éƒ¨åˆ†æ¢æˆæˆ‘çš„ç®—å­ |
| 2ï¸âƒ£generate_multiseg.py    | ã€3.05ã€‘å¯¹äºå½“å‰0-14çš„ç®—å­å¯ä»¥**éšæœºé€‰å¤šæ®µ**æ¥è¿›è¡Œèåˆï¼Œå†³ç­–é¡ºåº  â‘ æ˜¯å¦èåˆâ‘¡æ˜¯å¦è°ƒåº¦æ‰‹å†™ç®—å­â‘¢èåˆå‡ æ®µâ‘£å‡ æ®µçš„èåˆèŒƒå›´ | `python generate_multiseg.py B L S H W mask_id 0/1 0/1 seg_num [start, end]` |
| 3ï¸âƒ£translate.py            | ã€3.10ã€‘ç»™å®šè¾“å…¥value ( < 65535)  ç¿»è¯‘ä¸ºå¯¹åº”çš„äºŒè¿›åˆ¶æ•°ï¼Œç„¶åç¿»è¯‘ä¸ºå¯¹åº”çš„ æ®µæ•°n + næ®µ[start, end] | `python translate.py value`                                  |
| 4ï¸âƒ£generate_genidx.py      | ã€3.10ã€‘èåˆ2ï¸âƒ£3ï¸âƒ£                                               | `python generate_multiseg.py B L S H W mask_id 0/1 start`    |
| 5ï¸âƒ£traverse_generated.py   | ã€3.10ã€‘éå†4ï¸âƒ£ä¸­çš„ç”Ÿæˆçš„ä»£ç æ–‡ä»¶ï¼› æ’é”™,è§£å†³æŠ½å–ä»£ç çš„BUG; å¯»æ‰¾æœç´¢ç©ºé—´ | æœç´¢ç©ºé—´ åˆæ­¥ç¡®å®š$[32768, 49152] = [1000\thinspace0000\thinspace0000\thinspace0000, 1100\thinspace0000\thinspace0000\thinspace0000]$ |
| 6ï¸âƒ£                        |                                                              |                                                              |
|                          |                                                              |                                                              |



ä½¿ç”¨ChatGPTå®ç°valueç¼–ç çš„è¿‡ç¨‹ --- translate_demo.py
>ç°åœ¨æˆ‘æœ‰16ä¸ªä½ç½®posï¼Œpos0 - pos15ï¼Œå…¶ä¸­çš„æ¯ä¸€ä¸ªä½ç½®å¯ä»¥å–å€¼ä¸º0æˆ–1
>
>æŒ‰pos0-pos15çš„é¡ºåºå°†å…¶ä¸­çš„æ‰€æœ‰å€¼æ’åˆ—èµ·æ¥ï¼Œä¼šå¾—åˆ°ä¸€ä¸ªå€¼value
>
>
>
>æˆ‘æœ‰è¿™æ ·ä¸€ä¸ªç¿»è¯‘çš„éœ€æ±‚ï¼Œå°†è¿™ä¸ªå€¼valueç¿»è¯‘ä¸ºä¸‹é¢çš„ä¸€ç»„æ•°ï¼š
>
>[num] [pos0] [segment_num] [start_1] [end_1] ... [start_n] [end_n]
>
>è¯´æ˜ï¼š
>
>1. ç¿»è¯‘çš„è¦æ±‚æ˜¯ï¼šå½“ pos_iå’Œpos_i+1çš„å€¼ç›¸åŒæ—¶ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºä»–ä»¬æ˜¯ä¸€ä¸ªsegmentï¼Œå½“pos_iåˆ°pos_i+nçš„å€¼éƒ½ç›¸åŒï¼Œé‚£ä¹ˆä»–ä»¬éƒ½æ˜¯ä¸€æ®µã€‚
>2. [num]æ˜¯valueä»äºŒè¿›åˆ¶æ•° ï¼Œç”±pos0-pos15ç»„æˆçš„16ä½å­—ç¬¦ä¸²ç¿»è¯‘è€Œæ¥çš„ä¸€ä¸ªæ•´æ•°å€¼
>3. [pos0]å°±æ˜¯ pos0çš„å–å€¼ï¼Œå³0æˆ–1
>4. ä»¥ä¸Šçš„[start_n] [end_n]çš„ç»„æ•°ï¼Œå–å†³äºsegment_numçš„æ•°é‡ï¼Œä¾‹å¦‚segment_num = 1é‚£ä¹ˆ[start_n] [end_n]å¯¹åªæœ‰1ç»„å³[start_1] [end_1]ï¼›segment_num = 3é‚£ä¹ˆ[start_n] [end_n]å¯¹æœ‰3ç»„å³[start_1] [end_1] [start_2] [end_2] [start_3] [end_3]
>5. æˆ‘ä¼šç»™ä½ ä¸€æ®µè¿ç»­çš„è¾“å…¥ï¼Œæ˜¯pos0-pos15çš„å€¼ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸²é•¿åº¦ä¸º16çš„ç”±01ç»„æˆçš„å­—ç¬¦ä¸²
>
>
>
>ä¸¾ä¾‹ï¼š
>
>1. è¾“å…¥æ˜¯0001101010101010æ—¶ï¼Œç¿»è¯‘ç»“æœæ˜¯6826 0 2 1 2 3 4
>2. è¾“å…¥æ˜¯0000010101010101æ—¶ï¼Œç¿»è¯‘ç»“æœæ˜¯1365 0 1 1 4
>3. è¾“å…¥æ˜¯0011111010010110æ—¶ï¼Œç¿»è¯‘ç»“æœæ˜¯16022 0 3 2 6 9 10 13 14
>4. è¾“å…¥æ˜¯0101010101010101æ—¶ï¼Œç¿»è¯‘ç»“æœæ˜¯21845 0 0 



é’ˆå¯¹äº

éå†ä¸€éï¼Œæœç´¢ç©ºé—´ï¼š

+ ä½¿ç”¨æ‰‹å†™ç®—å­ï¼š[32768, 49152]
+ ä¸ä½¿ç”¨æ‰‹å†™ç®—å­ï¼š[16384, 24576] æ°å¥½æ˜¯ä¸Šé¢çš„ä¸€åŠ



# 5 - ä¸Šå±‚ - é‡‡æ ·æœç´¢

ç”¨XGboostæ¥è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼Œåšåˆ°æˆ‘ç»™å‡ºä¸€ä¸ª16ä½çš„å­—ç¬¦ä¸²ï¼Œè¾“å‡ºåé¢çš„å­—ç¬¦ä¸²

æ¯ä¸€ä¸ªXGboostè®­ç»ƒçš„ç»“æœéƒ½æ˜¯é’ˆå¯¹äºå½“å‰å‚æ•°ä¸‹çš„ï¼ˆbatch_size, seq_len , **mask**ï¼‰

> ç°åœ¨æœ‰è¿™æ ·ä¸€ä¸ªç”¨XGboostè®­ç»ƒçš„éœ€æ±‚ï¼Œæˆ‘å¸Œæœ›è¿™ä¸ªXgBooståˆ†ç±»å™¨ä¸ºæˆ‘è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä¸»è¦åŠŸèƒ½æ˜¯å¾—åˆ°ä¸€ä¸ªè¾“å…¥16ä½2è¿›åˆ¶çš„å­—ç¬¦ä¸²ï¼Œèƒ½å¤Ÿç»™æˆ‘è¿”å›ä¸€ä¸ªé¢„æµ‹çš„å€¼valueï¼Œå¹¶ä¸”æœ‰ä¸€ä¸ªå…³äºå…³äºè¿™ä¸ªvalueå€¼åœ¨æ€»ä½“ä¸­å±äºï¼ˆHigh Performanceï¼‰1æˆ–è€…ï¼ˆLow Performanceï¼‰0çš„é¢„æµ‹ã€‚
>
> æˆ‘ç»™åˆ°ä½ ä¸€ä¸ªæ•°æ®é›†ï¼Œè¿™ä¸ªæ•°æ®é›†çš„ç»„æˆæ˜¯ ä¸€ä¸ª16ä½çš„äºŒè¿›åˆ¶å­—ç¬¦ä¸²ï¼Œå’Œä¸€ä¸ªå€¼valueã€‚æ³¨æ„è¿™äº›æ•°æ®ä¸­valueå€¼è¶Šå°ï¼Œåˆ™æ˜¯High Performanceï¼Œè¶Šå¤§åˆ™å±äºLow Performanceã€‚
> æ€»å…±æœ‰æ•°ç™¾å¯¹è¿™æ · â€œå­—ç¬¦ä¸² - valueå¯¹â€ï¼Œè¿™ä¸ªæ•°æ®é›†çš„åç§°ä¸º"train_data_xgboost.txt"ï¼Œé‡Œé¢çš„æ•°æ®å¦‚ä¸‹å½¢å¼
>
> 1111100011001100   54.524
> 0100010111011101   55.053
> 0100110000010101   57.406
>
> æ‰€ä»¥å¯¹äºè¿™ä¸ªxgboostçš„è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ï¼Œèƒ½å¤Ÿåšåˆ°ï¼šæˆ‘è¾“å…¥ä¸€ä¸ª16ä½çš„ äºŒè¿›åˆ¶å­—ç¬¦ä¸²ï¼Œå®ƒè¾“å‡ºä¸€ä¸ªé¢„æµ‹å€¼valueï¼Œå¹¶å‘Šè¯‰æˆ‘è¿™ä¸ªå€¼å±äºHigh Performance 1 æˆ–è€… Low Performance 0
>
> æ ·ä¾‹è¾“å…¥ï¼š0100010111011101
>
> æ ·ä¾‹è¾“å‡ºï¼š54.524 1

